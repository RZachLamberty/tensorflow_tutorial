{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorflow debugger\n",
    "\n",
    "following [this](https://www.tensorflow.org/programmers_guide/debugger)\n",
    "\n",
    "the `tensorflow` debugger is called `tfdbg`, and is a `curses`-based cli. *because* it is `curses`-based, I won't be able to do much of the walkthrough here in the shell. I'll put my extra thoughts in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wrapping `tensorflow` sessions with `tfdbg`\n",
    "\n",
    "to use `tfdbg`, the first step is to wrap the session object in a debugger wrapper:\n",
    "\n",
    "```python\n",
    "from tensorflow.python import debug as tf_debug\n",
    "\n",
    "sess = tf_debug.LocalCLIDebugWrapperSession(sess)\n",
    "```\n",
    "\n",
    "or, using the full context manager:\n",
    "\n",
    "```python\n",
    "with tf_debug.LocalCLIDebugWrapperSession(tf.Session()) as sess:\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python import debug as tf_debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for an example of this in action, check out [`debug_mnist.py`, L127](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/debug/examples/debug_mnist.py#L127)\n",
    "\n",
    "some debugging checks are so common that they have been added to the `tf.python.debug.lib.debug_data` module (e.g.: `tfdbg.has_inf_or_nan`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## debugging model training with `tfdbg`\n",
    "\n",
    "the [`debug_mnist.py`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/debug/examples/debug_mnist.py) code has a cli flag built in to activate `--debug` mode. under the hood, this is a switch for using the `LocalCLIDebugWrapperSession` we discussed above, and thereby launching the `curses` interface for interactive debugging.\n",
    "\n",
    "once this has been activated, we are dropped into the program at the [*first* invocation `sess.run()`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/debug/examples/debug_mnist.py#L136) post-wrapper (note: there could be many such invocations and we'd be dropped into the program for each)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tfdbg` `cli` frequently-used commands\n",
    "\n",
    "this is a very good basic summary table of commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### other features of the `tfdbg` `cli`\n",
    "\n",
    "nothing to add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### finding `nan`s and `inf`s\n",
    "\n",
    "the `run` subcommand allows you to apply a condition filter after every step (analogous to conditional breakpoints):\n",
    "\n",
    "```\n",
    "run -f has_inf_or_nan\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the `has_inf_or_nan` filter *exists* because it was explicitly written out as `python` code (in the debug library itself, apparently; I can't see it anywhere) and was registered as a tensor filter in the default `LocalCLIDebugWrapperSession`. to add *your own* filter:\n",
    "\n",
    "```python\n",
    "def my_filter_callable(datum, tensor):\n",
    "    return len(tensor.shape) == 0 and tensor == 0.0\n",
    "\n",
    "sess.add_tensor_filter('my_filter', my_filter_callable)\n",
    "```\n",
    "\n",
    "will allow you to write `run -f my_filter` in the `tfdbg` interface. follow the following two docstrings down the rabbit hole to understand what `datum` and `tensor` are in the above (hint: `tensor` is a `np` array, which is generally good enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_debug.LocalCLIDebugWrapperSession.add_tensor_filter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_debug.DebugDumpDir.find?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the discussion here walks the user how to navigate toward the source of a *known* problem (obviously, that's taking as granted the greater half of the battle). the basic steps are:\n",
    "\n",
    "1. **filter tensors for problem**: use the `run -f` or `lt -f has_inf_or_nan` command to identify the problematic tensors\n",
    "1. **loop** to find the problematic input / operation:\n",
    "    1. **debug tensors**: use `pt` on the \"first\" / originating offending tensor, and within that the regex searching command `/(inf|nan)` to find the offending entries\n",
    "    1. **debug operations that created problem tensor**: this tensor was the output of a node operation; investigate that operation with `node_info`\n",
    "        1. in particular, identify the inputs to that operation\n",
    "    1. **debug inputs to problematic operation**: use `pt` on the input(s) of that operation\n",
    "    1. **repeat**: iterate the above steps until you think you know which input was a problem and why\n",
    "1. **identify problematic source code**: once you've identified the problematic input / operation, find the origin in the source code with `node_info -t` (traceback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fixing the problem\n",
    "\n",
    "source code had manual calcualtion of crossentropy:\n",
    "\n",
    "```python\n",
    "diff = -(y_ * tf.log(y))\n",
    "```\n",
    "\n",
    "use the builtin instead:\n",
    "\n",
    "```python\n",
    "diff = tf.losses.sparse_softmax_cross_entropy(labels=y_, logits=logits)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## debugging `tf-learn` estimators and experiments\n",
    "\n",
    "the whole point of the `tfdbg.LocalCLIDebugWrapperSession` is that it directly wraps the `tensorflow` session object. this is a problem for some of the higher-level apis where the `session` is obscured from the user -- how do we insert the debugger into those programs?\n",
    "\n",
    "the answer is `tfdbg` hooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sidebar about difference between `tf-learn` and the \"regular\" estimators\n",
    "\n",
    "this documentation presents a discussion about the `tf-learn` elements -- these are located in the `tf.contrib.learn` package. I *think* that modules estimator modules from this package are \"graduated\" to the core library in `tf.estimator` once they reach a stable point, so we should be able to treat them interchangeably in the long run, but in the short run some of the things you might find yourself using are `tf.contrib.learn` estimators.\n",
    "\n",
    "here's a quick diversion on the types of classifiers / estimators / regressor available in each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflearn_cers = {\n",
    "    _\n",
    "    for _ in dir(tf.contrib.learn)\n",
    "    if any(kw in _ for kw in ['Classifier', 'Estimator', 'Regressor'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfe_cers = {\n",
    "    _\n",
    "    for _ in dir(tf.estimator)\n",
    "    if any(kw in _ for kw in ['Classifier', 'Estimator', 'Regressor'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items in tf-learn but not in estimators:\n",
      "\tBaseEstimator\n",
      "\tDNNEstimator\n",
      "\tDNNLinearCombinedEstimator\n",
      "\tDynamicRnnEstimator\n",
      "\tLinearEstimator\n",
      "\tLogisticRegressor\n",
      "\n",
      "items in estimators but not in tf-learn:\n",
      "\tBaselineClassifier\n",
      "\tBaselineRegressor\n",
      "\tBoostedTreesClassifier\n",
      "\tBoostedTreesRegressor\n",
      "\tEstimatorSpec\n",
      "\n",
      "items in both:\n",
      "\tDNNClassifier\n",
      "\tDNNLinearCombinedClassifier\n",
      "\tDNNLinearCombinedRegressor\n",
      "\tDNNRegressor\n",
      "\tEstimator\n",
      "\tLinearClassifier\n",
      "\tLinearRegressor\n"
     ]
    }
   ],
   "source": [
    "print('items in tf-learn but not in estimators:')\n",
    "for module in sorted(tflearn_cers.difference(tfe_cers)):\n",
    "    print('\\t{}'.format(module))\n",
    "\n",
    "print('\\nitems in estimators but not in tf-learn:')\n",
    "for module in sorted(tfe_cers.difference(tflearn_cers)):\n",
    "    print('\\t{}'.format(module))\n",
    "\n",
    "print('\\nitems in both:')\n",
    "for module in sorted(tfe_cers.intersection(tflearn_cers)):\n",
    "    print('\\t{}'.format(module))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "of course, having a named object in both modules doesn't mean the code is identical -- just a suggestion that the two are related"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### debugging `tf.contrib.learn` estimators\n",
    "\n",
    "`tfdbg` can access the `fit` and `evaluate` methods of `tf-learn` `Estimator` objects because those object methods allow for `hooks` via the `monitor` argument:\n",
    "\n",
    "```python\n",
    "from tensorflow.python import debug as tf_debug\n",
    "\n",
    "# Create a LocalCLIDebugHook and use it as a monitor when calling fit().\n",
    "hooks = [tf_debug.LocalCLIDebugHook()]\n",
    "\n",
    "# `classifier` is an instance of one of the classifier\n",
    "# classes in `tf.contrib.learn`\n",
    "classifier.fit(x=training_set.data,\n",
    "               y=training_set.target,\n",
    "               steps=1000,\n",
    "               monitors=hooks)\n",
    "\n",
    "accuracy_score = classifier.evaluate(x=test_set.data,\n",
    "                                     y=test_set.target,\n",
    "                                     hooks=hooks)[\"accuracy\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the example module is built-in to [`debug_tflearn_iris.py`](https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/python/debug/examples/debug_tflearn_iris.py) and can be investiagated via the command\n",
    "\n",
    "```\n",
    "python -m tensorflow.python.debug.examples.debug_tflearn_iris --debug\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### debugging `tf.contrib.learn` experiments\n",
    "\n",
    "we have a lot of experience so far with the `experiments` api, but there is a different api available in `tf.contrib.learn`: `Experiment`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.contrib.learn.Experiment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "directly from the docs:\n",
    "\n",
    "> THIS CLASS IS DEPRECATED. See\n",
    "[contrib/learn/README.md](https://www.tensorflow.org/code/tensorflow/contrib/learn/README.md)\n",
    "for general migration instructions.\n",
    "\n",
    "looks like experiments has been migrated to `tf.estimator.train_and_evaluate`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "basically, this section of the docs are too old and have been deprecated. I am inferring (I hope correctly) that the `hooks` are now passed to the `tf.estimator.TrainSpec` and `tf.estimator.EvalSpec`.\n",
    "\n",
    "the new \"experiment\" interface is `tf.estimator.train_and_evaluate`, and that takes as arguments an `estimator`, and then a `TrainSpec` and `EvalSpec`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.estimator.train_and_evaluate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "those specs themselves take `hooks`, which would indicate to me that they are debug-able:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.estimator.TrainSpec?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## debugging `keras` models with `tfdbg`\n",
    "\n",
    "and what if we want to use the `keras` api? simple: tell `keras` to use a wrapped session:\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import debug as tf_debug\n",
    "\n",
    "tf.keras.backend.set_session(tf_debug.LocalCLIDebugWrapperSession(tf.Session()))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## debugging tf-slim with `tfdbg`\n",
    "\n",
    "what if you're using yet another fucking higher level api, `tf-slim`, defined in `tf.contrib.slim`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.contrib.slim.learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I WILL SKIP THIS SECTION**: per this SO comment but a tf developer, slim is basically deprecated and should be fully avoided: https://github.com/tensorflow/tensorflow/issues/16182#issuecomment-372397483"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### debugging training in `tf-slim`\n",
    "\n",
    "**I WILL SKIP THIS SECTION**: per this SO comment but a tf developer, slim is basically deprecated and should be fully avoided: https://github.com/tensorflow/tensorflow/issues/16182#issuecomment-372397483"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### debugging evaluation in `tf-slim`\n",
    "\n",
    "**I WILL SKIP THIS SECTION**: per this SO comment but a tf developer, slim is basically deprecated and should be fully avoided: https://github.com/tensorflow/tensorflow/issues/16182#issuecomment-372397483"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## offline debugging of remotely-running sessions\n",
    "\n",
    "what to do if you don't have terminal access to a running session? use the `offline_analyzer` binary of `tfdbg`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### debugging remote `tf.sessions`\n",
    "\n",
    "suppose you have a `tf.Session` connected to a remote service already existing. every time you want to `run` that session, you have the ability to specify a `tf.RunOptions` options object. `tfdbg` has implemented a function which updates that object to watch the graph as it is being executed; to save tensors to a directory where they can be retroactively opened and examined (I believe that is what going on, at least!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is done with the following code:\n",
    "\n",
    "```python\n",
    "from tensorflow.python import debug as tf_debug\n",
    "\n",
    "# ... Code where your session and graph are set up...\n",
    "\n",
    "run_options = tf.RunOptions()\n",
    "tf_debug.watch_graph(\n",
    "      run_options,\n",
    "      session.graph,\n",
    "      debug_urls=[\"file:///shared/storage/location/tfdbg_dumps_1\"]\n",
    ")\n",
    "# Be sure to specify different directories for different run() calls.\n",
    "\n",
    "session.run(fetches, feed_dict=feeds, options=run_options)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we are presupposing that this was done for multiple run calls and the program has run its course (probably incorrectly at that). those files were written to the server which remotely executed the graph.\n",
    "\n",
    "**here's hoping you actually have file access to those debug directories!**\n",
    "\n",
    "you actually need to access those directories to run `tfdbg` against them. this means that if you don't have shared directory access, you're kinda effed.\n",
    "\n",
    "if you *do* have access,\n",
    "\n",
    "```\n",
    "python -m tensorflow.python.debug.cli.offline_analyzer \\\n",
    "    --dump_dir=/shared/storage/location/tfdbg_dumps_1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `c++` and other languages\n",
    "\n",
    "blah blah modify `debug_options` field of `RunOptions` blah blah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### debugging remotely-running `tf-learn` estimators and experiments\n",
    "\n",
    "above we debugged *local* estimators using the `tf_debug.LocalCLIDebugHook` `hooks`. for a *remote* estimator we can use the `DumpingDebugHook`, which will do the same sort of thing as the session dumps: write outputs to files and then post-facto ingest them:\n",
    "\n",
    "```python\n",
    "# Let your BUILD target depend on \"//tensorflow/python/debug:debug_py\n",
    "# (You don't need to worry about the BUILD dependency if you are using a pip\n",
    "#  install of open-source TensorFlow.)\n",
    "from tensorflow.python import debug as tf_debug\n",
    "\n",
    "hooks = [tf_debug.DumpingDebugHook(\"/shared/storage/location/tfdbg_dumps_1\")]\n",
    "```\n",
    "\n",
    "and after files have been written to **some shared location**:\n",
    "\n",
    "```\n",
    "python -m tensorflow.python.debug.cli.offline_analyzer \\\n",
    "    --dump_dir=\"/shared/storage/location/tfdbg_dumps_1/run_<epoch_timestamp_microsec>_<uuid>\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## frequently asked questions\n",
    "\n",
    "a bunch of more or less interesting stuff, but one big one: there is a `tensorboard` plugin for `tfdbg`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summary\n",
    "\n",
    "`tfdbg` is a pretty well-featured debugging console application that provides you with tools to step through individual `tf.Session.run` calls and investigate the produced tensors at each stage. this documentation provides a quick overview of the most relevant commands and outlines how to use them in some probably-common use cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

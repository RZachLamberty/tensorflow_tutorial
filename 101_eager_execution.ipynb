{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eager execution\n",
    "\n",
    "following along with [this](https://www.tensorflow.org/programmers_guide/eager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[2.]]\n",
    "m = tf.matmul(x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2, shape=(1, 1), dtype=float32, numpy=array([[4.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m = [[4.]]\n"
     ]
    }
   ],
   "source": [
    "print('m = {}'.format(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=5, shape=(2, 2), dtype=int32, numpy=\n",
       "array([[1, 2],\n",
       "       [3, 4]], dtype=int32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([\n",
    "    [1, 2],\n",
    "    [3, 4]\n",
    "])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=8, shape=(2, 2), dtype=int32, numpy=\n",
       "array([[2, 3],\n",
       "       [4, 5]], dtype=int32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.add(a, 1)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=10, shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 2,  6],\n",
       "       [12, 20]], dtype=int32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  6],\n",
       "       [12, 20]], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.multiply(a, b)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfe = tf.contrib.eager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## control flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fizzbuzz(max_num):\n",
    "    counter = tf.constant(0)\n",
    "    for num in range(max_num):\n",
    "        num = tf.constant(num)\n",
    "        if int(num % 3) == 0 and int(num % 5) == 0:\n",
    "            print('FizzBuzz')\n",
    "        elif int(num % 3) == 0:\n",
    "            print('Fizz')\n",
    "        elif int(num % 5) == 0:\n",
    "            print('Buzz')\n",
    "        else:\n",
    "            print(num)\n",
    "        counter += 1\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FizzBuzz\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "Fizz\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "Buzz\n",
      "Fizz\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "Fizz\n",
      "Buzz\n",
      "tf.Tensor(11, shape=(), dtype=int32)\n",
      "Fizz\n",
      "tf.Tensor(13, shape=(), dtype=int32)\n",
      "tf.Tensor(14, shape=(), dtype=int32)\n",
      "FizzBuzz\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "tf.Tensor(17, shape=(), dtype=int32)\n",
      "Fizz\n",
      "tf.Tensor(19, shape=(), dtype=int32)\n",
      "Buzz\n",
      "Fizz\n",
      "tf.Tensor(22, shape=(), dtype=int32)\n",
      "tf.Tensor(23, shape=(), dtype=int32)\n",
      "Fizz\n",
      "Buzz\n",
      "tf.Tensor(26, shape=(), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=242, shape=(), dtype=int32, numpy=27>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fizzbuzz(27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## building models\n",
    "\n",
    "### custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySimpleLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, output_units):\n",
    "        self.output_units = output_units\n",
    "        \n",
    "    def build(self, input):\n",
    "        self.kernel = self.add_variable(\n",
    "            \"kernel\",\n",
    "            [input.shape[-1], self.output_units]\n",
    "        )\n",
    "    \n",
    "    def call(self, input):\n",
    "        return tf.matmul(input, self.kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what methods did we just define?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.layers.Layer.build?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.layers.Layer.call?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regular-ass layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=(784,)),\n",
    "    tf.keras.layers.Dense(10),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### complicated-ass models\n",
    "\n",
    "you can inherit in `keras` and it is dopetown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(units=10)\n",
    "        self.dense2 = tf.keras.layers.Dense(units=10)\n",
    "    \n",
    "    def call(self, input):\n",
    "        result = self.dense1(input)\n",
    "        result = self.dense2(result)\n",
    "        result = self.dense2(result)  # <-- note: reusing dense2 layer\n",
    "        return result\n",
    "\n",
    "model = MNISTModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eager training\n",
    "\n",
    "### gradients\n",
    "\n",
    "we need to be able to calculate and record gradients. `tensorflow` does this with a `GradientTape` object, which will record the gradient of a given function at every input value for which that function is invoked.\n",
    "\n",
    "it is unclear if this is for eager execution *only*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(1, 1) dtype=float32, numpy=array([[1.]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = tfe.Variable([[1.0]])\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=304, shape=(1, 1), dtype=float32, numpy=array([[0.5]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".5 * w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=308, shape=(1, 1), dtype=float32, numpy=array([[1.]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    loss = w * w\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=315, shape=(1, 1), dtype=float32, numpy=array([[2.]], dtype=float32)>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad = tape.gradient(loss, [w])\n",
    "grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<tf.Tensor: id=1508, shape=(1, 1), dtype=float32, numpy=array([[0.]], dtype=float32)>],\n",
       " [<tf.Tensor: id=1524, shape=(1, 1), dtype=float32, numpy=array([[2.]], dtype=float32)>],\n",
       " [<tf.Tensor: id=1540, shape=(1, 1), dtype=float32, numpy=array([[4.]], dtype=float32)>],\n",
       " [<tf.Tensor: id=1556, shape=(1, 1), dtype=float32, numpy=array([[6.]], dtype=float32)>],\n",
       " [<tf.Tensor: id=1572, shape=(1, 1), dtype=float32, numpy=array([[8.]], dtype=float32)>],\n",
       " [<tf.Tensor: id=1588, shape=(1, 1), dtype=float32, numpy=array([[10.]], dtype=float32)>],\n",
       " [<tf.Tensor: id=1604, shape=(1, 1), dtype=float32, numpy=array([[12.]], dtype=float32)>],\n",
       " [<tf.Tensor: id=1620, shape=(1, 1), dtype=float32, numpy=array([[14.]], dtype=float32)>],\n",
       " [<tf.Tensor: id=1636, shape=(1, 1), dtype=float32, numpy=array([[16.]], dtype=float32)>],\n",
       " [<tf.Tensor: id=1652, shape=(1, 1), dtype=float32, numpy=array([[18.]], dtype=float32)>]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradlist = []\n",
    "for i in range(10):\n",
    "    w = tfe.Variable([[float(i)]])\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = w * w\n",
    "    gradlist.append(tape.gradient(loss, [w]))\n",
    "gradlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### example: shitty linear regression model with forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1677, shape=(1000,), dtype=float32, numpy=\n",
       "array([ 3.64652181e+00,  2.28102183e+00, -2.40652740e-01,  3.93023729e+00,\n",
       "        2.82786632e+00,  3.77242160e+00,  6.17322731e+00,  1.05803132e+00,\n",
       "        2.54766512e+00, -4.88282442e-01, -2.82695341e+00,  4.84145021e+00,\n",
       "       -1.68067813e+00,  1.20960021e+00,  6.70853138e+00,  6.31164670e-01,\n",
       "        3.07569718e+00,  1.79241931e+00,  2.23191571e+00,  2.32926559e+00,\n",
       "       -1.41559982e+00,  1.71928775e+00, -4.35607255e-01,  9.14053261e-01,\n",
       "        7.63299131e+00,  4.09155273e+00,  1.77412331e-01,  6.06801510e-01,\n",
       "        1.69252872e+00,  5.88237476e+00, -3.33578658e+00,  5.50017452e+00,\n",
       "        2.91740918e+00,  6.32875156e+00, -2.64434004e+00,  4.28190756e+00,\n",
       "        6.39332008e+00,  1.20916581e+00,  5.51986408e+00,  2.63368702e+00,\n",
       "        6.49455738e+00,  6.15780735e+00,  5.58228350e+00,  3.52789974e+00,\n",
       "        5.55755496e-02,  1.01956129e-01,  5.99886656e+00,  4.88607979e+00,\n",
       "        4.84475613e+00,  4.95513630e+00,  1.86514330e+00,  3.76117539e+00,\n",
       "        3.38304305e+00, -4.02361274e-01,  3.04465866e+00,  2.95454311e+00,\n",
       "        3.93786001e+00,  4.50446749e+00,  5.89801073e+00, -1.44192243e+00,\n",
       "        4.49694633e+00,  6.60564721e-01,  4.18530750e+00,  5.16951752e+00,\n",
       "        1.82704222e+00,  3.98289323e+00,  2.09940100e+00,  5.00253677e+00,\n",
       "       -1.46006823e+00,  6.59386873e-01,  2.82621121e+00,  2.42742419e+00,\n",
       "        7.73769474e+00, -7.31042087e-01,  2.36534977e+00,  3.94125366e+00,\n",
       "        6.60683107e+00,  6.19052315e+00,  1.74864626e+00, -3.70083690e-01,\n",
       "        5.42514420e+00,  5.98563862e+00, -1.12646449e+00,  9.47039986e+00,\n",
       "        7.54791260e+00,  4.46945429e-01,  8.11580753e+00,  5.29631519e+00,\n",
       "        5.19206047e+00, -2.10573435e-01,  5.39697552e+00,  6.80123043e+00,\n",
       "       -1.00120902e-02, -4.10541058e+00,  3.09259820e+00, -2.79954195e-01,\n",
       "        2.20099306e+00, -8.30421329e-01,  1.18888092e+00, -3.59122229e+00,\n",
       "        3.96372771e+00,  6.84137201e+00,  1.33522296e+00,  1.54353762e+00,\n",
       "        3.47226071e+00,  4.74996758e+00, -3.97367656e-01,  2.49749541e+00,\n",
       "       -1.41808736e+00,  4.13026428e+00,  1.08360493e+00, -3.21280241e+00,\n",
       "       -1.34863567e+00, -1.01232004e+00,  5.48787165e+00,  2.01014590e+00,\n",
       "        5.77284145e+00,  5.45084095e+00,  3.17887139e+00,  1.05074608e+00,\n",
       "       -1.62781882e+00,  1.07942319e+00,  2.43485498e+00,  2.79564452e+00,\n",
       "        3.56371951e+00,  4.00514221e+00, -1.16782331e+00,  2.00814342e+00,\n",
       "        3.26548266e+00,  2.06421995e+00,  1.05736887e+00, -2.93178630e+00,\n",
       "        1.15049267e+00, -3.84436786e-01, -1.55575192e+00,  1.58971024e+00,\n",
       "        2.14720678e+00,  4.48583698e+00, -1.54795790e+00,  1.54879940e+00,\n",
       "        4.39377928e+00,  2.35993719e+00,  1.58314252e+00,  7.00160599e+00,\n",
       "       -5.49385309e-01,  2.43094301e+00, -4.66424465e-01,  5.16662455e+00,\n",
       "        3.87579441e+00,  2.31131315e-02, -6.37959421e-01, -3.51698160e+00,\n",
       "        1.46863186e+00,  2.12704539e+00,  6.91410065e-01,  1.63860238e+00,\n",
       "        7.63933420e+00,  3.13503146e+00,  1.99818206e+00,  2.45083094e+00,\n",
       "        4.08248568e+00,  4.02032137e-02, -9.31039512e-01,  1.11217260e+00,\n",
       "        4.45554304e+00,  4.00496960e-01, -1.61462665e+00,  6.80813408e+00,\n",
       "        2.81831622e+00,  3.70165586e-01,  3.11303139e+00,  6.02725792e+00,\n",
       "        3.96344948e+00,  4.65709257e+00,  5.49982214e+00,  2.72995162e+00,\n",
       "        1.81378615e+00,  2.85363102e+00,  9.41908598e-01,  1.51434898e-01,\n",
       "       -4.01412785e-01,  3.02869558e+00,  4.64928913e+00,  3.11023092e+00,\n",
       "       -1.73596025e-01,  3.45780778e+00,  4.65744853e-01, -3.55016541e+00,\n",
       "        4.50353622e+00,  2.71127582e-01, -4.03635454e+00,  1.41574097e+00,\n",
       "        9.47343349e-01, -1.09482265e+00,  1.89382946e+00,  2.42540693e+00,\n",
       "        3.73717594e+00,  1.27191317e+00,  2.30559731e+00,  6.07349157e-01,\n",
       "        2.80410147e+00,  3.43965101e+00,  3.38387871e+00,  3.95089483e+00,\n",
       "        3.99473214e+00,  5.11497021e-01, -1.82775903e+00,  2.21173882e+00,\n",
       "       -3.35757828e+00,  1.12323427e+00,  6.32859468e-01,  4.01507020e-02,\n",
       "       -9.73163247e-02,  3.71278715e+00,  2.61687899e+00,  8.90839195e+00,\n",
       "       -2.06910205e+00,  3.99963593e+00,  1.09468222e-01,  2.19697785e+00,\n",
       "        5.05405951e+00,  4.60340214e+00,  2.03597474e+00,  2.28756046e+00,\n",
       "        5.05595744e-01,  5.08653831e+00,  6.30322218e-01,  2.38789606e+00,\n",
       "        1.85604310e+00, -1.64511490e+00,  2.30158520e+00,  1.94802034e+00,\n",
       "        2.94758034e+00,  2.62167430e+00, -1.29858565e+00, -3.51719832e+00,\n",
       "        2.02318978e+00,  1.55369544e+00, -9.08403754e-01,  1.16536963e+00,\n",
       "       -1.22444630e-02,  7.20115232e+00,  1.90009964e+00,  2.33418441e+00,\n",
       "        3.03798079e-01,  2.85886407e+00,  3.97295117e+00,  3.77991557e-01,\n",
       "        7.44348884e-01, -1.40186214e+00,  4.14919853e+00,  4.46456861e+00,\n",
       "        2.41215682e+00, -1.47643924e+00, -1.60096049e-01,  2.74723148e+00,\n",
       "        3.70774031e+00,  2.30920506e+00,  7.14851236e+00,  5.89523458e+00,\n",
       "        1.07865829e+01,  1.63085270e+00,  3.56467080e+00,  2.27713728e+00,\n",
       "       -2.22611964e-01,  2.14190125e+00,  4.01062059e+00,  1.13570070e+00,\n",
       "        2.72205758e+00,  2.60609913e+00,  2.56856799e+00, -2.61965275e+00,\n",
       "       -3.91988307e-01,  2.49998868e-01,  6.79404211e+00, -2.32469845e+00,\n",
       "       -3.30691278e-01,  3.23912215e+00,  2.43774235e-01,  3.12762976e+00,\n",
       "        4.11525726e+00,  2.35971737e+00,  4.56342411e+00,  1.70781291e+00,\n",
       "        5.52698135e+00,  2.28583145e+00,  3.40497684e+00,  1.26005650e+00,\n",
       "        2.50319862e+00, -2.08166242e-01, -8.31566453e-01,  3.74798584e+00,\n",
       "        1.82390928e+00,  4.85852909e+00, -3.26792836e+00,  4.68275499e+00,\n",
       "        1.69568866e-01,  3.44230890e+00,  1.84363902e+00, -3.97177529e+00,\n",
       "       -2.33312726e-01,  5.26625061e+00,  7.80646443e-01,  6.29397106e+00,\n",
       "        4.81850481e+00,  1.40964162e+00,  1.07565951e+00,  4.04987621e+00,\n",
       "        4.59340096e+00,  1.61031783e+00,  3.07796550e+00, -1.31116819e+00,\n",
       "        7.25782728e+00,  3.01568246e+00, -2.74933410e+00, -1.49922788e+00,\n",
       "       -1.00374765e+01,  7.01956463e+00,  9.79119182e-01,  1.34094501e+00,\n",
       "       -9.05159712e-01, -2.21717072e+00, -6.55257821e-01,  3.71900773e+00,\n",
       "        5.68262386e+00,  2.48971033e+00,  4.01601171e+00, -8.24478209e-01,\n",
       "       -2.63060474e+00, -1.14095688e+00,  5.56394863e+00,  3.07148647e+00,\n",
       "        1.03978205e+00,  3.88165653e-01,  4.24105835e+00,  4.73349333e+00,\n",
       "       -2.12923145e+00,  3.41604567e+00, -3.12715364e+00, -1.82307804e+00,\n",
       "        1.13204670e+00, -5.94687283e-01, -4.55082607e+00,  1.19561410e+00,\n",
       "        9.85579872e+00,  7.36480236e-01,  4.10501003e+00, -3.08230734e+00,\n",
       "       -2.15832710e+00,  5.44254637e+00, -1.73628342e+00,  3.52900743e-01,\n",
       "        8.43572807e+00,  5.32231855e+00,  2.60061884e+00,  5.58016777e-01,\n",
       "        3.09362411e+00,  8.03791165e-01,  1.68085539e+00, -3.14774966e+00,\n",
       "       -1.31799054e+00,  6.98597431e+00,  4.71356869e-01,  2.44640684e+00,\n",
       "        1.53120828e+00,  4.77782488e+00,  1.44573045e+00,  2.04178286e+00,\n",
       "        5.60795403e+00,  5.97735357e+00,  4.00905514e+00,  3.46414876e+00,\n",
       "        8.37821674e+00,  9.88893270e-01,  2.40366602e+00,  7.65926242e-02,\n",
       "        1.46178126e-01, -4.27350950e+00,  4.17882395e+00,  4.19669914e+00,\n",
       "        2.35227990e+00, -2.43911162e-01,  1.43743145e+00,  1.45141792e+00,\n",
       "       -1.22831917e+00,  9.59784031e-01,  2.96439499e-01,  6.08012581e+00,\n",
       "        1.74650836e+00, -1.59767783e+00,  6.83117867e-01,  1.90955639e+00,\n",
       "        3.19402003e+00,  5.83285809e+00,  4.85193825e+00,  2.81552029e+00,\n",
       "        2.43804961e-01,  4.22283125e+00,  5.77551174e+00,  2.89951658e+00,\n",
       "        2.75909758e+00, -3.91697049e-01,  5.82921922e-01,  6.49880838e+00,\n",
       "        5.45934868e+00,  3.02473187e+00,  5.36231470e+00,  2.15090895e+00,\n",
       "       -4.81934071e+00,  4.55812156e-01,  5.55471611e+00,  7.89198780e+00,\n",
       "       -1.11580372e-01,  3.38123441e+00,  9.68463802e+00, -2.50526595e+00,\n",
       "        6.49259520e+00,  3.25663376e+00, -2.50915575e+00,  1.10334671e+00,\n",
       "        3.18300581e+00, -1.69215751e+00, -1.97185659e+00, -1.78053212e+00,\n",
       "        2.78504968e-01,  1.44492161e+00,  1.31762755e+00,  3.57944155e+00,\n",
       "        6.20961571e+00,  4.56426620e+00,  6.93386173e+00,  5.35969782e+00,\n",
       "        3.56471157e+00,  6.50068760e-01,  3.92719817e+00, -1.40404487e+00,\n",
       "        7.81835556e+00, -5.09323478e-01, -3.37281227e+00, -1.09371769e+00,\n",
       "        5.41795111e+00,  1.26897439e-01,  3.77306175e+00,  3.38733578e+00,\n",
       "        4.44547558e+00,  7.85268736e+00,  4.75719833e+00,  2.21433592e+00,\n",
       "        5.14107704e+00, -5.31610310e-01,  4.22685003e+00,  1.11196244e+00,\n",
       "        9.58321762e+00,  2.12513185e+00,  3.78744316e+00,  4.82284927e+00,\n",
       "        2.13901925e+00,  4.02511787e+00,  3.76337862e+00, -1.91488552e+00,\n",
       "       -6.75715971e+00, -7.61752188e-01, -1.59058249e+00,  2.94802618e+00,\n",
       "        4.89737034e+00,  1.78921628e+00,  8.33297539e+00,  9.61370915e-02,\n",
       "        1.12553847e+00,  1.29810190e+00,  3.23951602e+00, -6.80592299e-01,\n",
       "        5.61042976e+00,  2.31421304e+00,  6.05573273e+00,  6.96126699e+00,\n",
       "        5.45265436e+00,  9.83709717e+00,  3.44601750e+00,  3.88581181e+00,\n",
       "       -4.56833315e+00, -3.08756590e+00,  6.12383008e-01, -6.60996079e-01,\n",
       "        3.11018872e+00,  1.02821243e+00,  2.86376810e+00,  3.82197762e+00,\n",
       "       -1.70306754e+00,  5.18634939e+00,  4.13755655e+00,  1.66335440e+00,\n",
       "        1.72545016e+00,  5.09581625e-01,  7.52150536e+00,  8.42613316e+00,\n",
       "       -3.70438671e+00,  6.09903479e+00,  4.93706369e+00,  1.00309455e+00,\n",
       "        2.57950306e+00,  4.30901861e+00,  6.03097796e-01,  9.17730427e+00,\n",
       "        5.06037378e+00,  1.84726584e+00,  6.91079712e+00, -1.77745819e+00,\n",
       "        4.49497938e+00,  3.52067399e+00,  4.59581900e+00, -1.45441771e+00,\n",
       "       -3.28676486e+00,  5.34332180e+00, -1.76760578e+00, -3.41381192e+00,\n",
       "        1.44997168e+00, -4.84233379e+00,  1.31618217e-01, -5.55585146e-01,\n",
       "       -1.03894556e+00,  4.64447927e+00,  2.91049337e+00,  7.16449213e+00,\n",
       "        5.03049231e+00,  3.47497106e-01,  2.71780789e-02, -2.69835353e-01,\n",
       "       -6.27878904e+00,  1.98864841e+00, -1.38140070e+00, -4.85912800e-01,\n",
       "       -5.07782888e+00,  4.45475483e+00,  3.72266722e+00,  1.22123682e+00,\n",
       "        4.25268650e+00,  1.90827465e+00, -3.77489471e+00,  5.75265265e+00,\n",
       "       -1.71645463e+00,  4.03754425e+00,  1.81906486e+00,  1.24106777e+00,\n",
       "        1.34778500e-01, -2.02005357e-02,  1.95338738e+00, -4.80312347e+00,\n",
       "        1.51764154e-01,  4.09665871e+00,  5.28006840e+00,  1.03645790e+00,\n",
       "        3.21984291e+00,  8.50978661e+00,  2.52306271e+00,  2.57693577e+00,\n",
       "        2.96803737e+00,  1.95400143e+00,  6.13488007e+00,  4.36493826e+00,\n",
       "        5.87725973e+00, -1.78980279e+00,  1.20381981e-01,  7.40387440e+00,\n",
       "        5.83460331e-02, -1.36425066e+00,  5.83303571e-02,  4.36542988e+00,\n",
       "        8.24252892e+00, -1.48168123e+00,  1.99912739e+00, -1.04162939e-01,\n",
       "       -6.11384273e-01,  3.85224056e+00,  2.39101887e-01,  2.75360656e+00,\n",
       "        4.41992283e-02,  6.30412483e+00,  3.12557983e+00, -5.12946033e+00,\n",
       "        4.05631542e+00, -8.89961362e-01,  4.71330690e+00,  3.54005766e+00,\n",
       "       -8.77823770e-01, -7.87240326e-01,  7.95249104e-01, -1.50459266e+00,\n",
       "       -2.06735596e-01,  3.50814629e+00,  3.27042174e+00, -9.24067736e-01,\n",
       "       -8.21894705e-01, -1.08099973e+00,  1.03555858e+00,  3.33589506e+00,\n",
       "        2.26344824e+00,  8.46538067e-01, -3.71047831e+00, -9.21000719e-01,\n",
       "       -3.08284497e+00,  5.19562435e+00,  1.92255509e+00,  2.92216849e+00,\n",
       "        3.37403011e+00,  2.21519470e+00,  2.14399472e-01,  3.41341782e+00,\n",
       "       -8.58729959e-01,  1.31316304e+00, -3.46053290e+00,  4.15780544e+00,\n",
       "        5.14414501e+00,  5.95426846e+00,  2.57612753e+00,  3.16441154e+00,\n",
       "        1.79275298e+00,  1.73856425e+00, -4.55135298e+00, -1.15820217e+00,\n",
       "       -5.99745560e+00,  3.07785892e+00,  2.58799267e+00,  3.87795854e+00,\n",
       "        5.62351751e+00,  2.24133587e+00, -1.24943662e+00,  5.96461916e+00,\n",
       "        2.10151029e+00, -2.50471020e+00, -3.15616179e+00, -2.99899578e+00,\n",
       "       -2.86694288e+00,  4.00157022e+00,  3.06132698e+00,  7.76447010e+00,\n",
       "       -1.00254738e+00,  3.03524399e+00,  7.36542988e+00, -1.45557523e-01,\n",
       "        2.58206177e+00, -3.19026336e-02, -1.27451777e-01, -1.73458731e+00,\n",
       "       -4.56329823e+00,  3.44870996e+00,  1.81191456e+00,  6.91895342e+00,\n",
       "        3.83623123e+00,  7.14521456e+00,  1.74618080e-01,  3.01283479e-01,\n",
       "       -1.19661927e+00,  1.64585090e+00,  4.11880207e+00,  3.57316041e+00,\n",
       "       -5.19224107e-01,  1.91956186e+00, -2.05496144e+00,  1.14252377e+00,\n",
       "        5.64387417e+00,  5.63987112e+00,  4.35792494e+00,  3.77922869e+00,\n",
       "        3.62588227e-01,  5.01803815e-01,  5.57754612e+00,  5.25974393e-01,\n",
       "        4.07751608e+00,  8.92669559e-01, -1.32481515e-01,  4.37315166e-01,\n",
       "        8.93007994e-01,  9.63830948e-02,  3.91053677e+00,  4.34497166e+00,\n",
       "        7.05781412e+00, -1.84488833e-01, -5.11554778e-01, -4.08722162e-02,\n",
       "        3.36831450e+00,  1.09286261e+00,  3.90330005e+00,  4.19056988e+00,\n",
       "        6.86328602e+00,  3.77476811e+00, -3.87970209e-02, -2.29683623e-01,\n",
       "        5.66806793e-02,  4.95742035e+00,  7.46569633e+00,  5.97655487e+00,\n",
       "        3.68896413e+00,  3.48892450e+00,  3.59057736e+00,  3.69060349e+00,\n",
       "        1.34807241e+00, -2.42960870e-01,  2.59000158e+00,  4.01251698e+00,\n",
       "        3.92656851e+00,  6.80858564e+00, -2.48881602e+00, -4.61579895e+00,\n",
       "        3.38072801e+00, -2.79902488e-01,  2.38701284e-01,  2.77257514e+00,\n",
       "        4.97509909e+00,  8.53989244e-01,  2.16864634e+00,  1.32527769e+00,\n",
       "        6.16109514e+00, -2.72236407e-01,  6.56599402e-02,  6.41401291e+00,\n",
       "       -1.63497508e+00, -4.29938227e-01,  3.28823066e+00,  1.74009752e+00,\n",
       "        2.08905625e+00, -1.76737320e+00,  5.48918343e+00,  4.64494753e+00,\n",
       "        2.71467113e+00,  1.46049595e+00, -7.72716522e-01, -1.79169428e+00,\n",
       "       -1.09970260e+00, -2.86409807e+00,  1.19846880e+00,  7.96165824e-01,\n",
       "        2.53946137e+00, -4.75846195e+00, -1.04608309e+00, -1.60996675e+00,\n",
       "        5.20236444e+00,  2.40198421e+00,  2.83418417e+00,  5.61191320e-01,\n",
       "       -2.32663012e+00,  5.50427294e+00, -2.18465996e+00,  7.59748125e+00,\n",
       "        6.68187666e+00, -4.65715885e-01,  3.41400909e+00,  7.63513625e-01,\n",
       "        3.41501331e+00,  4.50968981e-01,  9.74267006e+00,  3.66750026e+00,\n",
       "       -1.33428919e+00, -9.60610151e-01,  1.27623653e+00,  4.56498742e-01,\n",
       "       -1.04742563e+00,  2.41414738e+00,  4.40243053e+00,  5.65856171e+00,\n",
       "        4.27122068e+00,  3.63520479e+00, -9.55871344e-01, -6.19705248e+00,\n",
       "       -1.76207674e+00,  2.42326713e+00,  7.44777012e+00, -1.40518987e+00,\n",
       "        3.79316068e+00,  1.45269322e+00, -1.64492702e+00,  9.31936562e-01,\n",
       "        5.60061836e+00,  3.07435894e+00,  5.47791004e+00,  5.59118927e-01,\n",
       "       -2.04865074e+00,  1.00760901e+00,  1.64174438e+00,  9.17729664e+00,\n",
       "        8.90687943e-01,  2.01815295e+00, -4.59448457e-01,  4.82463503e+00,\n",
       "        5.50117588e+00, -1.05948937e+00,  1.79331672e+00,  2.00488806e+00,\n",
       "        1.05297554e+00, -2.69429350e+00,  2.69262505e+00,  3.12285328e+00,\n",
       "       -1.20908034e+00,  3.12819934e+00,  2.36173844e+00, -3.08462358e+00,\n",
       "       -1.56007731e+00,  2.44530535e+00,  3.93216062e+00,  2.56259084e-01,\n",
       "        5.18571186e+00,  6.47413063e+00, -8.81773233e-01,  3.87442017e+00,\n",
       "       -5.16634762e-01, -9.50142324e-01,  4.48999453e+00,  1.05700552e-01,\n",
       "        2.49220657e+00,  1.96180022e+00,  7.23620892e+00,  3.57954288e+00,\n",
       "       -3.10269904e+00,  1.18872106e-01,  2.58200836e+00,  3.16000080e+00,\n",
       "        2.03726435e+00,  3.39858413e-01,  1.31834567e+00,  3.72835922e+00,\n",
       "        4.91707420e+00,  6.51667833e+00, -2.69775414e+00,  4.27657652e+00,\n",
       "       -3.03822351e+00,  1.25848734e+00,  2.10289598e+00,  3.16346288e+00,\n",
       "        6.47940278e-01,  1.51244700e+00,  5.60140610e+00,  2.75781488e+00,\n",
       "        7.16310918e-01, -3.13687229e+00,  8.27503800e-01,  2.36060834e+00,\n",
       "        4.10590506e+00,  4.25692797e+00, -1.57226324e+00,  1.88233817e+00,\n",
       "        6.60817575e+00,  5.59983921e+00,  1.38798165e+00, -5.77237701e+00,\n",
       "        3.42337322e+00,  1.06328225e+00, -7.54967690e-01, -2.10519695e+00,\n",
       "        1.72209144e+00, -2.61897087e-01,  3.20790672e+00,  1.86547732e+00,\n",
       "        3.44960570e+00,  2.29855657e+00,  1.72109807e+00,  1.55804157e+00,\n",
       "        2.99036217e+00,  1.61987007e+00, -1.14934552e+00,  8.41161442e+00,\n",
       "        3.55885077e+00,  2.17392349e+00,  6.49650860e+00,  2.15553790e-01,\n",
       "        1.63656831e+00,  5.47624731e+00, -2.59290075e+00,  5.29871893e+00,\n",
       "        4.93053865e+00,  1.34139287e+00,  5.20782375e+00,  3.38480139e+00,\n",
       "        2.06142235e+00,  4.41138983e+00,  4.34011841e+00,  1.45698571e+00,\n",
       "       -4.12914425e-01,  5.23189402e+00,  9.39444923e+00, -4.34221864e-01,\n",
       "        4.92556334e+00,  4.79437494e+00,  5.74676609e+00,  4.10643768e+00,\n",
       "        6.25653982e+00,  3.44850469e+00, -4.81118107e+00,  8.63802433e-01,\n",
       "        5.55551410e-01,  2.25393796e+00,  5.91900945e-01, -1.74268818e+00,\n",
       "       -1.32711601e+00,  7.85697460e+00,  3.86800504e+00,  2.14767408e+00,\n",
       "        1.85439181e+00,  2.13607168e+00,  4.38016772e-01,  2.24842024e+00,\n",
       "        2.39523435e+00,  1.01133752e+00,  9.40883160e-03,  2.82382774e+00,\n",
       "       -3.53141856e+00,  7.53340185e-01,  3.03297549e-01, -1.08551204e+00,\n",
       "       -2.53974378e-01,  6.45111179e+00,  7.83749580e-01,  6.90923071e+00,\n",
       "        2.14366984e+00, -1.99442983e+00,  2.98094702e+00,  1.49290454e+00,\n",
       "       -6.73689961e-01, -5.97333908e-01, -3.52289170e-01, -3.21128297e+00,\n",
       "        1.44532585e+00, -5.30048013e-01,  2.02460504e+00,  2.91637588e+00,\n",
       "        4.29928637e+00,  7.59951019e+00,  4.78002357e+00,  9.08915758e-01,\n",
       "       -3.21352172e+00, -9.28089142e-01,  3.99265385e+00,  1.23029959e+00,\n",
       "        2.23650408e+00,  5.04018021e+00,  2.58622813e+00,  2.74354887e+00,\n",
       "       -4.72071457e+00,  1.25553608e+00,  1.79478669e+00, -4.53137922e+00,\n",
       "       -3.72335148e+00, -7.57316709e-01, -2.37949324e+00,  9.30383492e+00,\n",
       "        5.50005484e+00,  3.52240729e+00,  5.70533276e+00,  7.29031658e+00,\n",
       "        6.21557808e+00, -1.86735487e+00, -1.12976861e+00,  1.05242910e+01,\n",
       "        2.30152220e-01,  1.74431348e+00,  1.69094801e-01,  1.91960812e-01,\n",
       "        6.68442786e-01, -2.49678230e+00,  7.82055020e-01, -3.68324971e+00,\n",
       "        6.06471920e+00,  6.52031136e+00,  2.17577314e+00, -1.82198048e+00,\n",
       "        3.63810015e+00,  7.48119831e-01,  8.20195484e+00,  4.97326899e+00,\n",
       "       -7.10692286e-01,  2.43061543e+00, -2.76444936e+00, -3.55776250e-01,\n",
       "       -2.25551343e+00,  9.65095758e-02,  3.83747721e+00,  1.05989480e+00,\n",
       "       -6.70956230e+00,  2.51565123e+00,  3.12963665e-01, -1.80014443e+00,\n",
       "        5.81300640e+00, -3.91959786e+00, -7.58091927e-01,  5.29060555e+00,\n",
       "       -2.18340039e+00,  5.13560414e-01,  1.96243656e+00,  2.46738696e+00,\n",
       "        6.23215961e+00,  7.07321167e+00,  4.30195045e+00, -2.70463848e+00,\n",
       "        1.41708326e+00, -2.11035967e-01,  2.70732689e+00, -4.71369863e-01,\n",
       "        3.43113232e+00,  5.08732653e+00,  3.24195027e+00, -7.18549490e-02],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_EXAMPLES = 1000\n",
    "training_inputs = tf.random_normal([NUM_EXAMPLES])\n",
    "noise = tf.random_normal([NUM_EXAMPLES])\n",
    "training_outputs = 3 * training_inputs + 2 + noise\n",
    "training_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.,   5.,  20.,  81., 201., 257., 233., 139.,  50.,  13.]),\n",
       " array([-10.03747654,  -7.95507059,  -5.87266464,  -3.79025869,\n",
       "         -1.70785275,   0.3745532 ,   2.45695915,   4.5393651 ,\n",
       "          6.62177105,   8.704177  ,  10.78658295]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(training_outputs.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(input, weight, bias):\n",
    "    return input * weight + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(weights, biases):\n",
    "    error = prediction(training_inputs, weights, biases) - training_outputs\n",
    "    return tf.reduce_mean(tf.square(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(weights, biases):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(weights, biases)\n",
    "    return tape.gradient(loss_value, [weights, biases])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bullshit init vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = 200\n",
    "learning_rate = 0.01\n",
    "W = tfe.Variable(5.)\n",
    "B = tfe.Variable(10.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initial loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1703, shape=(), dtype=float32, numpy=68.337906>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(W, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at step 000: 65.687\n",
      "loss at step 020: 29.966\n",
      "loss at step 040: 13.967\n",
      "loss at step 060: 6.798\n",
      "loss at step 080: 3.585\n",
      "loss at step 100: 2.145\n",
      "loss at step 120: 1.498\n",
      "loss at step 140: 1.209\n",
      "loss at step 160: 1.079\n",
      "loss at step 180: 1.020\n"
     ]
    }
   ],
   "source": [
    "for i in range(train_steps):\n",
    "    dW, dB = grad(W, B)\n",
    "    W.assign_sub(dW * learning_rate)\n",
    "    B.assign_sub(dB * learning_rate)\n",
    "    if i % 20 == 0:\n",
    "        print('loss at step {:03d}: {:.3f}'.format(i, loss(W, B)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "final loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=9006, shape=(), dtype=float32, numpy=0.99471706>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(W, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "final W and B:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=3.0519025>,\n",
       " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.152522>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W, B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### example: multi-layer mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(1), Dimension(1), Dimension(784)])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = tf.zeros([1, 1, 784])\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=9097, shape=(1, 1, 10), dtype=float32, numpy=array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model(batch)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### just loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(image):\n",
    "    image = tf.decode_raw(image, tf.uint8)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.reshape(image, [784])\n",
    "    return image / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_label(label):\n",
    "    label = tf.decode_raw(label, tf.uint8)\n",
    "    label = tf.reshape(label, [])\n",
    "    return tf.to_int32(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset(train_or_test):\n",
    "    if train_or_test == 'train':\n",
    "        prefix = 'train'\n",
    "    elif train_or_test == 'test':\n",
    "        prefix = 't10k'\n",
    "    else:\n",
    "        raise ValueError(\"only 'train' and 't10k' are supported for `train_or_test`\")\n",
    "    \n",
    "    images_file = '/data/mnist_yl/{}-images-idx3-ubyte'.format(prefix)\n",
    "    labels_file = '/data/mnist_yl/{}-labels-idx1-ubyte'.format(prefix)\n",
    "    \n",
    "    images = tf.data.FixedLengthRecordDataset(\n",
    "        images_file, 28 * 28, header_bytes=16\n",
    "    ).map(decode_image)\n",
    "    labels = tf.data.FixedLengthRecordDataset(\n",
    "        labels_file, 1, header_bytes=8\n",
    "    ).map(decode_label)\n",
    "    return tf.data.Dataset.zip((images, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = dataset('train') \\\n",
    "    .shuffle(60000) \\\n",
    "    .repeat(4) \\\n",
    "    .batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### defining the model loss and gradient shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, x, y):\n",
    "    prediction = model(x)\n",
    "    return tf.losses.sparse_softmax_cross_entropy(labels=y, logits=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(model, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets)\n",
    "    return tape.gradient(loss_value, model.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = iter(dataset_train).next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initial loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=9173, shape=(), dtype=float32, numpy=2.4276183>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(model, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.apply_gradients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at step 0000: 2.434\n",
      "loss at step 0200: 2.046\n",
      "loss at step 0400: 2.066\n",
      "loss at step 0600: 1.840\n",
      "loss at step 0800: 1.697\n",
      "loss at step 1000: 1.667\n",
      "loss at step 1200: 1.522\n",
      "loss at step 1400: 1.564\n",
      "loss at step 1600: 1.311\n",
      "loss at step 1800: 1.188\n",
      "loss at step 2000: 1.216\n",
      "loss at step 2200: 0.919\n",
      "loss at step 2400: 1.016\n",
      "loss at step 2600: 1.155\n",
      "loss at step 2800: 0.854\n",
      "loss at step 3000: 1.081\n",
      "loss at step 3200: 0.716\n",
      "loss at step 3400: 0.669\n",
      "loss at step 3600: 1.005\n",
      "loss at step 3800: 0.506\n",
      "loss at step 4000: 0.744\n",
      "loss at step 4200: 0.706\n",
      "loss at step 4400: 0.677\n",
      "loss at step 4600: 0.656\n",
      "loss at step 4800: 0.629\n",
      "loss at step 5000: 0.621\n",
      "loss at step 5200: 0.361\n",
      "loss at step 5400: 0.618\n",
      "loss at step 5600: 0.524\n",
      "loss at step 5800: 0.419\n",
      "loss at step 6000: 0.463\n",
      "loss at step 6200: 0.454\n",
      "loss at step 6400: 0.514\n",
      "loss at step 6600: 0.421\n",
      "loss at step 6800: 0.487\n",
      "loss at step 7000: 0.550\n",
      "loss at step 7200: 0.319\n",
      "loss at step 7400: 0.395\n"
     ]
    }
   ],
   "source": [
    "for (i, (x, y)) in enumerate(dataset_train):\n",
    "    grads = grad(model, x, y)\n",
    "    optimizer.apply_gradients(\n",
    "        grads_and_vars=zip(grads, model.variables),\n",
    "        global_step=tf.train.get_or_create_global_step()\n",
    "    )\n",
    "    \n",
    "    if i % 200 == 0:\n",
    "        print('loss at step {:04d}: {:.3f}'.format(i, loss(model, x, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "final loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=663178, shape=(), dtype=float32, numpy=0.51715356>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(model, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### on a gpu\n",
    "\n",
    "*if* this is running in a gpu, you may un-comment and execute the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/gpu:0'):\n",
    "#     for (i, (x, y)) in enumerate(dataset_train):\n",
    "#         optimizer.minimize(\n",
    "#             lambda: loss(model, x, y),\n",
    "#             global_step=tf.train.get_or_create_global_step()\n",
    "#         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### variables and optimizers\n",
    "\n",
    "I can't tell whether the purpose discussed here -- storing mutable tensors for access during automatic differentiation while models are training -- is the *sole* purpose or just *one good* purpose.\n",
    "\n",
    "the docstring for `tf.Variable` is actually pretty useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.Variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "basically, variables are ways of maintaining state across different session runs. they can be passed around between different operations within sessions as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the tutorial the presents a preferable alternative method of defining models for training. given the original linear regression model:\n",
    "\n",
    "```python\n",
    "NUM_EXAMPLES = 1000\n",
    "training_inputs = tf.random_normal([NUM_EXAMPLES])\n",
    "noise = tf.random_normal([NUM_EXAMPLES])\n",
    "training_outputs = training_inputs * 3 + 2 + noise\n",
    "\n",
    "def prediction(input, weight, bias):\n",
    "  return input * weight + bias\n",
    "\n",
    "def loss(weights, biases):\n",
    "  error = prediction(training_inputs, weights, biases) - training_outputs\n",
    "  return tf.reduce_mean(tf.square(error))\n",
    "\n",
    "def grad(weights, biases):\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss_value = loss(weights, biases)\n",
    "  return tape.gradient(loss_value, [weights, biases])\n",
    "\n",
    "train_steps = 200\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Start with arbitrary values for W and B on the same batch of data\n",
    "W = tfe.Variable(5.)\n",
    "B = tfe.Variable(10.)\n",
    "\n",
    "print(\"Initial loss: {:.3f}\".format(loss(W, B)))\n",
    "\n",
    "for i in range(train_steps):\n",
    "  dW, dB = grad(W, B)\n",
    "  W.assign_sub(dW * learning_rate)\n",
    "  B.assign_sub(dB * learning_rate)\n",
    "  if i % 20 == 0:\n",
    "    print(\"Loss at step {:03d}: {:.3f}\".format(i, loss(W, B)))\n",
    "\n",
    "print(\"Final loss: {:.3f}\".format(loss(W, B)))\n",
    "print(\"W = {}, B = {}\".format(W.numpy(), B.numpy()))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we update this with a oop approach in which:\n",
    "\n",
    "1. the mutable weight and bias variables `W` and `B` are moved from geing global variables to model instance attributes\n",
    "1. the predict function is changed from a global function taking input, weight, and bias to a model instance method taking just inputs (weights and biases being instance attributes)\n",
    "1. the loss and gradient functions (which previously took weights and biases) are updated to take models, inputs, and targets (the assumption being that models have weights and biases\n",
    "1. the optimization portion utilizes built-in optimizer and gradient methods rather than hard-coding the updates\n",
    "\n",
    "\n",
    "things which remain the same:\n",
    "\n",
    "1. the random sampling for initial inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # above we just created global variables W and B; here we save them as\n",
    "        # model attributes\n",
    "        self.W = tfe.Variable(5., name='weight')\n",
    "        self.B = tfe.Variable(10., name='bias')\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        return inputs * self.W + self.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A toy dataset of points around 3 * x + 2\n",
    "NUM_EXAMPLES = 2000\n",
    "training_inputs = tf.random_normal([NUM_EXAMPLES])\n",
    "noise = tf.random_normal([NUM_EXAMPLES])\n",
    "training_outputs = training_inputs * 3 + 2 + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, inputs, targets):\n",
    "    error = model.predict(inputs) - targets\n",
    "    return tf.reduce_mean(tf.square(error))\n",
    "\n",
    "def grad(model, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets)\n",
    "    return tape.gradient(loss_value, [model.W, model.B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initial loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=663212, shape=(), dtype=float32, numpy=68.37149>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(model, training_inputs, training_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at step 000: 65.718\n",
      "loss at step 020: 29.973\n",
      "loss at step 040: 13.968\n",
      "loss at step 060: 6.802\n",
      "loss at step 080: 3.594\n",
      "loss at step 100: 2.157\n",
      "loss at step 120: 1.513\n",
      "loss at step 140: 1.225\n",
      "loss at step 160: 1.096\n",
      "loss at step 180: 1.038\n",
      "loss at step 200: 1.013\n",
      "loss at step 220: 1.001\n",
      "loss at step 240: 0.996\n",
      "loss at step 260: 0.993\n",
      "loss at step 280: 0.992\n"
     ]
    }
   ],
   "source": [
    "for i in range(300):\n",
    "    grads = grad(model, training_inputs, training_outputs)\n",
    "    optimizer.apply_gradients(\n",
    "        zip(grads, [model.W, model.B]),\n",
    "        global_step=tf.train.get_or_create_global_step()\n",
    "    )\n",
    "    \n",
    "    if i % 20 == 0:\n",
    "        print('loss at step {:03d}: {:.3f}'.format(i, loss(model, training_inputs, training_outputs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "final loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=673558, shape=(), dtype=float32, numpy=0.9919324>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(model, training_inputs, training_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "final weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.9956298, 2.0364199)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.W.numpy(), model.B.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use objects for state during eager execution\n",
    "\n",
    "### variables are objects\n",
    "\n",
    "one useful fact about eager execution: variables persist with their references. if references are removed the variables die. the example is\n",
    "\n",
    "```python\n",
    "with tf.device('gpu:0'):\n",
    "    v = tfe.Variable(tf.random_normal([1000, 1000]))\n",
    "    # do some shit -- v is taking up GPU memory\n",
    "    # do some more shit\n",
    "    # do even more shit -- v is still taking up GPU memory\n",
    "    v = None\n",
    "    # v is gone, no more GPU memory is being used\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### object-based saving\n",
    "\n",
    "any variable can be checkpointed using `tf.Checkpoint`. there is no discussion re: whether something other than a variable can be checkpointed or, for that matter, what exactly a variable is. again, check out the `tv.Variable` docstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.Variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=10.0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tfe.Variable(10.)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.contrib.eager.python.checkpointable_utils.Checkpoint at 0x7f4164576588>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = tfe.Checkpoint(x_var_name=x)\n",
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.assign(2.)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = checkpoint.save('/tmp/ckpt/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable '' shape=() dtype=float32, numpy=11.0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.assign(11.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.contrib.eager.python.checkpointable_utils.CheckpointLoadStatus at 0x7f4164576eb8>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.restore(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 12\r\n",
      "-rw-r--r-- 1 zlamberty 217 Jun 25 14:16 -1.data-00000-of-00001\r\n",
      "-rw-r--r-- 1 zlamberty 256 Jun 25 14:16 -1.index\r\n",
      "-rw-r--r-- 1 zlamberty  81 Jun 25 14:16 checkpoint\r\n"
     ]
    }
   ],
   "source": [
    "ll /tmp/ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we just demonstrated how we would checkpoint single variables. we can also checkpoint more than that (whole models, e.g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "checkpoint_dir = '/tmp/tensorflow_tutorial_model'\n",
    "if not os.path.isdir(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the keys in the **kwargs passed to `tfe.Checkpoint` are arbitrary\n",
    "# and become the name of the real rhs value within the checkpoint\n",
    "# object\n",
    "root = tfe.Checkpoint(\n",
    "    optimizer=optimizer,\n",
    "    model=model,\n",
    "    optimizer_step=tf.train.get_or_create_global_step()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/tensorflow_tutorial_model/ckpt-1'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root.save(file_prefix=checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.contrib.eager.python.checkpointable_utils.CheckpointLoadStatus at 0x7f4164591f98>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 12\r\n",
      "-rw-r--r-- 1 zlamberty 131 Jun 25 15:05 checkpoint\r\n",
      "-rw-r--r-- 1 zlamberty 410 Jun 25 15:05 ckpt-1.data-00000-of-00001\r\n",
      "-rw-r--r-- 1 zlamberty 356 Jun 25 15:05 ckpt-1.index\r\n"
     ]
    }
   ],
   "source": [
    "ll /tmp/tensorflow_tutorial_model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### object-oriented metrics\n",
    "\n",
    "metrics exist as objects that are callable, not as functions or values. update these metrics by passing arguments to the element via the `__call__` (i.e. `(...)`) method, and get actual results via teh `.result` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=673681, shape=(), dtype=float64, numpy=2.5>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = tfe.metrics.Mean(\"loss\")\n",
    "m(0)\n",
    "m(5)\n",
    "m.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=673693, shape=(), dtype=float64, numpy=5.5>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m([8, 9])\n",
    "m.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### summaries and tensorboard\n",
    "\n",
    "we use the `tf.contrib.summary` function to record information in a way that is ingestible via `tensorboard`, a visualization tool (generally distributed with, but not as a part of, `tensorflow`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.contrib.summary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the documentation (both online and in the docstring) only offer pseudo-code examples of how to create or register summaries. to reproduce them:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### summaries in eager execution\n",
    "\n",
    "from the web tutorial:\n",
    "\n",
    "```python\n",
    "writer = tf.contrib.summary.create_file_writer(logdir)\n",
    "global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "writer.set_as_default()\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "    global_step.assign_add(1)\n",
    "    \n",
    "    # some sort of `record_summaries` context is required \n",
    "    with tf.contrib.summary.record_summaries_every_n_global_steps(100):\n",
    "        # model model model model...\n",
    "        tf.contrib.summary.scalar('loss', loss)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from the docstrings:\n",
    "\n",
    "```python\n",
    "global_step = tf.train.get_or_create_global_step()\n",
    "summary_writer = tf.contrib.summary.create_file_writer(\n",
    "    train_dir,\n",
    "    flush_millis=10000\n",
    ")\n",
    "\n",
    "with summary_writer.as_default(), tf.contrib.summary.always_record_summaries():\n",
    "    # model code goes here\n",
    "    # and in it call\n",
    "    tf.contrib.summary.scalar(\"loss\", my_loss)\n",
    "    # In this case every call to tf.contrib.summary.scalar will generate a record\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### summaries in graph execution\n",
    "\n",
    "from the docstrings:\n",
    "\n",
    "```python\n",
    "global_step = tf.train.get_or_create_global_step()\n",
    "summary_writer = tf.contrib.summary.create_file_writer(\n",
    "    train_dir,\n",
    "    flush_millis=10000\n",
    ")\n",
    "\n",
    "with summary_writer.as_default(), tf.contrib.summary.always_record_summaries():\n",
    "    # model definition code goes here\n",
    "    # and in it call\n",
    "    tf.contrib.summary.scalar(\"loss\", my_loss)\n",
    "    # *EVERYTHING UP TO HERE IS the same between eager and graph execution\n",
    "    \n",
    "    # In this case every call to tf.contrib.summary.scalar will generate an op,\n",
    "    # note the need to run tf.contrib.summary.all_summary_ops() to make sure these\n",
    "    # ops get executed.\n",
    "    # ...\n",
    "    train_op = ....\n",
    "\n",
    "with tf.Session(...) as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    tf.contrib.summary.initialize(graph=tf.get_default_graph())\n",
    "    # ...\n",
    "    while not_done_training:\n",
    "        sess.run([train_op, tf.contrib.summary.all_summary_ops()])\n",
    "        # ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## advanced automatic differentiation topics\n",
    "\n",
    "here we investiage the `tf.GradientTape` function in a bit more detail, and particularly applications to different types of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dynamic models\n",
    "\n",
    "the example given here is a [\"backtracking line search\"](https://en.wikipedia.org/wiki/Backtracking_line_search), which is a minimization approach that seeks to find the distance along a search direction that you should jump to maximize some objective function (e.g. in gradient descent, given some extremely large initial jump size, \"backtrack\" until you find some acceptably small minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "tape.gradient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_search_step(fn, init_x, rate=1.0):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # to record a tensor you must call `tape.watch`\n",
    "        tape.watch(init_x)\n",
    "        \n",
    "        # variables, on the other hand, are automatically recorded\n",
    "        value = fn(init_x)\n",
    "    \n",
    "    grad, = tape.gradient(\n",
    "        target=value,  # tensor we wish to differentiate\n",
    "        sources=[init_x]  # the variables wrt which we differentiate\n",
    "    )\n",
    "    \n",
    "    grad_norm = tf.reduce_sum(grad * grad) ** 0.5\n",
    "    \n",
    "    init_value = value\n",
    "    print('init_x = {}'.format(init_x))\n",
    "    print('init_grad = {}'.format(grad))\n",
    "    print('init_grad_norm = {}'.format(grad_norm))\n",
    "    print('init_value = {}'.format(value))\n",
    "    print('init_rate = {}'.format(rate))\n",
    "    while value > init_value - rate * grad_norm:\n",
    "        x = init_x - rate * grad\n",
    "        print()\n",
    "        print('x = {} - {} * {} = {}'.format(init_x.numpy(), rate, grad, x))\n",
    "        value = fn(x)\n",
    "        rate /= 2.0\n",
    "        print('x = {}'.format(x))\n",
    "        print('grad = {}'.format(grad))\n",
    "        print('grad_norm = {}'.format(grad_norm))\n",
    "        print('value = {}'.format(value))\n",
    "        print('rate = {}'.format(rate))\n",
    "    \n",
    "    return x, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = lambda x: x * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_x = tfe.Variable(1000.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_x = <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1000.0>\n",
      "init_grad = 2000.0\n",
      "init_grad_norm = 2000.0\n",
      "init_value = 1000000.0\n",
      "init_rate = 1\n",
      "\n",
      "x = 1000.0 - 1 * 2000.0 = -1000.0\n",
      "x = -1000.0\n",
      "grad = 2000.0\n",
      "grad_norm = 2000.0\n",
      "value = 1000000.0\n",
      "rate = 0.5\n",
      "\n",
      "x = 1000.0 - 0.5 * 2000.0 = 0.0\n",
      "x = 0.0\n",
      "grad = 2000.0\n",
      "grad_norm = 2000.0\n",
      "value = 0.0\n",
      "rate = 0.25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=674899, shape=(), dtype=float32, numpy=0.0>,\n",
       " <tf.Tensor: id=674904, shape=(), dtype=float32, numpy=0.0>)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_search_step(fn, init_x, rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why isn't the `grad` variable updated? it looks like it's defined in terms of the `init_x` value, in which case it is repeatedly being updated *to the same value* -- I think that's wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### additional function to compute gradients\n",
    "\n",
    "it is possible that we don't want to use `tfe.Variables` (as in, only tensors and functions) when calculating gradients -- especially if have an exact version of a gradient (I expect this is a good deal faster than automatic gradient computation). the docs reference two functions:\n",
    "\n",
    "1. `tfe.gradients_functions`: given a function, this returns a function which is the gradient of that input function\n",
    "1. `tfe.value_and_gradients_functions`: same as above, but also returns the value of the input function at the invoked input (i.e. $f(x)$ and $f'(x)$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(x):\n",
    "    return tf.multiply(x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = tfe.gradients_function(square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=674922, shape=(), dtype=float32, numpy=9.0>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "square(3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=674928, shape=(), dtype=float32, numpy=6.0>]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad(3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=674940, shape=(), dtype=float32, numpy=2.0>]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradgrad = tfe.gradients_function(lambda x: grad(x)[0])\n",
    "gradgrad(3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradgradgrad = tfe.gradients_function(lambda x: gradgrad(x)[0])\n",
    "gradgradgrad(3.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note this will also work with discontinuities (how?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myabs(x):\n",
    "    return x if x > 0. else -x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = tfe.gradients_function(myabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=310, shape=(), dtype=float32, numpy=1.0>]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad(3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=674965, shape=(), dtype=float32, numpy=-1.0>]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad(-3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=674979, shape=(), dtype=int32, numpy=-1>]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### custom gradients\n",
    "\n",
    "the claim here is that sometimes you need to override the basic gradient calculation method (specifically, it seems, to prevent against explosion or asymptoting). in particular, this is how you can provide optimized calculations (e.g. re-use of inputs in the derivative itself, common any time we'll be using exponentials e.g.). they provide the following examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def clip_gradient_by_norm(x, norm):\n",
    "    y = tf.identity(x)\n",
    "    def grad_fn(dresult):\n",
    "        return [tf.clip_by_norm(dresult, norm), None]\n",
    "    return y, grad_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and here, showing how clipping actually makes a difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log1pexp(x):\n",
    "    return tf.log(1 + tf.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_log1pexp = tfe.gradients_function(log1pexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=675016, shape=(), dtype=float32, numpy=0.5>]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_log1pexp(0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and for `x=100` we get a grad of `nan` (overflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=675024, shape=(), dtype=float32, numpy=nan>]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_log1pexp(100.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=675026, shape=(), dtype=float32, numpy=inf>"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.exp(100.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can create a custom gradient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.custom_gradient?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as the docstring above makes clear, this decorator allows you to define a function which has a custom default behavior. you define the function itself and its gradient, and then calls to `tfe.gradient_function` will return your custom gradient instead of the built-in gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def log1pexp(x):\n",
    "    # calculate the exponential of x as a separate tensor\n",
    "    # this can be re-used in both the funciton and its derivative\n",
    "    e = tf.exp(x)\n",
    "    \n",
    "    # the function value is tf.log(1 + e) and will be defined\n",
    "    # inline below\n",
    "    \n",
    "    # the derivative, on the other hand, must be defined here as \n",
    "    # a function of input grad_ys values\n",
    "    def grad(dy):\n",
    "        # the easiest version would be (e / (1 + e)) but I bet that's \n",
    "        # computationally less desirable than this version\n",
    "        return dy * (1 - 1 / (1 + e))\n",
    "    \n",
    "    return tf.log(1 + e), grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after defining the above, the function `tfe.gradients_function` will point to our custom gradient function defined above rather than the default calculated gradient function. at the current time I can't figure out how to demonstrate this, unfortunately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_log1pexp = tfe.gradients_function(log1pexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=675036, shape=(), dtype=float32, numpy=0.5>]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_log1pexp(0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and for `x=100` we get the expected value (1) and no overflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=675046, shape=(), dtype=float32, numpy=1.0>]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_log1pexp(100.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## performance\n",
    "\n",
    "according to the docs, **all** computation in eager execution mode is done on the gpu if available. it looks like the docker container is taking care of this for me successfully!\n",
    "\n",
    "we can control this more granularly with teh `tf.device` context manager.\n",
    "\n",
    "here's their example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to multiply a (1000, 1000) matrix by itself 200 times:\n",
      "CPU: 1.4114584922790527 secs\n",
      "GPU: not found\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def measure(x, steps):\n",
    "    # TensorFlow initializes a GPU the first time it's used, exclude from timing.\n",
    "    tf.matmul(x, x)\n",
    "    start = time.time()\n",
    "    for i in range(steps):\n",
    "        x = tf.matmul(x, x)\n",
    "        _ = x.numpy()  # Make sure to execute op and not just enqueue it\n",
    "    end = time.time()\n",
    "    return end - start\n",
    "\n",
    "shape = (1000, 1000)\n",
    "steps = 200\n",
    "print(\"Time to multiply a {} matrix by itself {} times:\".format(shape, steps))\n",
    "\n",
    "# Run on CPU:\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    print(\"CPU: {} secs\".format(measure(tf.random_normal(shape), steps)))\n",
    "\n",
    "# Run on GPU, if available:\n",
    "if tfe.num_gpus() > 0:\n",
    "    with tf.device(\"/gpu:0\"):\n",
    "        print(\"GPU: {} secs\".format(measure(tf.random_normal(shape), steps)))\n",
    "else:\n",
    "    print(\"GPU: not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "they also mention that you can create distributed copies of the same tensor on different devices, which is cool:\n",
    "\n",
    "```python\n",
    "x = tf.random_normal([10, 10])\n",
    "\n",
    "x_gpu0 = x.gpu()\n",
    "x_cpu = x.cpu()\n",
    "\n",
    "_ = tf.matmul(x_cpu, x_cpu)\n",
    "_ = tf.matmul(x_gpu, x_gpu)\n",
    "\n",
    "if tfe.num_gpus() > 1:\n",
    "    x_gpu1 = x.gpu(1)\n",
    "    _ = tf.matmul(x_gpu1, x_gpu1)\n",
    "```\n",
    "\n",
    "reproduced below for users on a gpu machine (uncomment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = tf.random_normal([10, 10])\n",
    "\n",
    "# x_gpu0 = x.gpu()\n",
    "# x_cpu = x.cpu()\n",
    "\n",
    "# _ = tf.matmul(x_cpu, x_cpu)    # Runs on CPU\n",
    "# _ = tf.matmul(x_gpu0, x_gpu0)  # Runs on GPU:0\n",
    "\n",
    "# if tfe.num_gpus() > 1:\n",
    "#     x_gpu1 = x.gpu(1)\n",
    "#     _ = tf.matmul(x_gpu1, x_gpu1)  # Runs on GPU:1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### benchmarks\n",
    "\n",
    "toss-off statement about how eager execution is comparable to graph execution in terms of performance fro \"compute-heavy\" models (e.g. is ResNet50). the more the burden shifts from computation to optimization and code-path calculation, the worse eager execution looks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## work with graphs\n",
    "\n",
    "the want you to use the graph execution paradigm, folks, they list the advantages of the graph execution method and it basically boils down to compilation into `c++` base code and distribution / replication handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write compatible code\n",
    "\n",
    "they offer some tips for how to write eager-execution-able code that is *also* graph executible\n",
    "\n",
    "1. use `tf.data` for inputs instead of queues (I'm not sure what a queue is, nor how we used them here)\n",
    "1. use OOP api in `tf.keras` (`layers` and `Model`)\n",
    "    1. explained reason: they have \"explicit storage for variables\"\n",
    "    \n",
    "they suggest you develop / iterate in eager execution mode and then checkpoint / import into graph execution for model deployment. this is interesting as an idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use eager exectuion in a graph environment\n",
    "\n",
    "they show how you can selectively use eager execution from within graph execution (which is super useful to know!)\n",
    "\n",
    "```python\n",
    "def my_py_func(x):\n",
    "    x = tf.matmul(x, x)\n",
    "    print(x)\n",
    "    return x\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    x = tf.placeholder(dtype=tf.float32)\n",
    "    \n",
    "    # eager function from within graph execution right here\n",
    "    pf = tfe.py_func(my_py_func, [x], tf.float32)\n",
    "    \n",
    "    sess.run(pf, feed_dict={x: [[2.0]]})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summary\n",
    "\n",
    "okay, there was a ton of info covered here. the basic gist is that there are two modes of execution in tensorflow\n",
    "\n",
    "1. **graph execution**: you define a computation graph and then, after the entire graph has been well defined, you ask tensorflow to initiate a session and perform the computation\n",
    "1. **eager execution**: a more `python`ic interactive method of developing code in the interpreter (and getting real-time updated to your commands\n",
    "\n",
    "this document focuses on *eager* execution. we cover the following topics\n",
    "\n",
    "1. one and only one time in a given `python` session you may run `tf.enable_eager_execution()`\n",
    "    1. this cannot be undone. you must kill the session\n",
    "1. you can write all tensorflow code as if you were writing regular `python` code\n",
    "    1. e.g. control flow with `if... else`, `print` statements, live evaluation of arithmetic operations\n",
    "1. you can more easily identify the results of training a model under this paradigm (that is, define models and immediately train them against observable, interactable data)\n",
    "1. there are standard ways of calculating gradients\n",
    "1. there are some differentiation tricks\n",
    "    1. this did not seem to have anything in particular to do with eager execution tbh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

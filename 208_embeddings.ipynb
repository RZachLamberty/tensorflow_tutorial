{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# embeddings\n",
    "\n",
    "following [this](https://www.tensorflow.org/programmers_guide/embedding)\n",
    "\n",
    "first of all, [this page](https://distill.pub/2016/misread-tsne/) and [this page](http://projector.tensorflow.org/) are flipping amazing.\n",
    "\n",
    "the docs define:\n",
    "\n",
    "> An **embedding** is a mapping from discrete objects, such as words, to vectors of real numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## embeddings in tensorflow\n",
    "\n",
    "they just describe how you make a bag of words embedding. that's it.\n",
    "\n",
    "assume we have already assigned an integer to every word in our vocab. this means we have a way of converting sentences to a mutable-length vector of integers `word_ids`. then we create an embedding lookup which is transforms \n",
    "\n",
    "```python\n",
    "word_embeddings = tf.get_variable(\n",
    "    \"word_embeddings\",\n",
    "    [vocabulary_size, embedding_size]\n",
    ")\n",
    "embedded_word_ids = tf.nn.embedding_lookup(\n",
    "    params=word_embeddings,  # complete embedding tensor, here a VOCAB x EMBEDDING array\n",
    "    ids=word_ids  # tensor with indices to be pulled out of embedding tensor\n",
    ")\n",
    "```\n",
    "\n",
    "`tf.nn.embedding_lookup` is a trainable tensor that will conver vector `word_ids` into vectors of `embedding_size` length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.nn.embedding_lookup?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualizing embeddings\n",
    "\n",
    "if you have created an embedding tensor such as the above, `tensorboard` can visualize it for you. which is cool.\n",
    "\n",
    "the tutorial here is pretty vague and it doesn't make sense to cover it without the example visualizer linked in the docs and at the top of the page, so go check that out instead of reading these summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summary\n",
    "\n",
    "+ tensorflow has some built-in support for embeddings\n",
    "+ tensorboard has some built-in support for *visualizing* embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mnist\n",
    "\n",
    "following along with [this](https://www.tensorflow.org/tutorials/layers). I'll be executing what I want in this directory, but also (as instructed) following along while building `cnn_mnist.py` in the neighboring directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import cnn_mnist\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting started\n",
    "\n",
    "they do a few things worth noting:\n",
    "\n",
    "+ they use the alias `tf`, common across `tensorflow` scripts\n",
    "+ they set the `logging` for `tf` to `INFO` level\n",
    "+ they add a dunder-main block calling `tf.app.run()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## intro to convolutional neural networks\n",
    "\n",
    "they break a cnn into three \"components\":\n",
    "\n",
    "1. convolutional layers, filters which summarize regions of data\n",
    "    1. refer to `relu` as a way of introducing nonlinearities\n",
    "1. pooling layers, downsample to reduce dimensionality\n",
    "    1. they say it's to reduce processing time, implying it's not *a priori* desirable (not sure if it is tbh)\n",
    "1. dense layers\n",
    "    1. these take filter/pool features and condense them to predictions/classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## building the cnn mnist classifier\n",
    "\n",
    "architecture:\n",
    "\n",
    "1. conv, 32 5x5, relu\n",
    "1. pooling, 2x2, stride 2\n",
    "1. conv, 64 5x5, relu\n",
    "1. pooling, 2x2, stride 2\n",
    "1. dense, 1024 nodes, dropout 0.4\n",
    "6. dense, 10, logits for predicted proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is assisted by the `tf.layers` module, specifically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.layers.conv2d?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.layers.max_pooling2d?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.layers.dense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "each is `tensor --> tensor`, so we add ops to the graph by passing layers into the next.\n",
    "\n",
    "here's the full code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(cnn_mnist)\n",
    "\n",
    "cnn_mnist.cnn_model_fn??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.estimator.Estimator?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's take a deep dive into the code for each layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input layer\n",
    "\n",
    "the first argument to `cnn_model_fn` is the feature collection, which can either be a single tensor or a dictionary of tensors. in this instance we are assuming (in code) that it is a dictionary (see `features[\"x\"]`). whatever shape the input tensor is, we want to reshape it to have a `[batch_size, image_height, image_width, channels]` shape (this is what is required for the 2d convolutional and pooling layers). `mnist` images are monocolored (`channels = 1`) and are 28 x 28 pixels (`image_{height,width} = 28`)\n",
    "\n",
    "we also use the automatic shape calculation sentinel `-1` so that we don't need to know the `batch_size` ahead of time\n",
    "\n",
    "```python\n",
    "input_layer = tf.reshape(features['x'], [-1, 28, 28, 1])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convolutional layer #1\n",
    "\n",
    "this is pretty straightfoward thanks to `tf.layers.conv2d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.layers.conv2d?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we wish to make 32 5x5 filters with `relu` activation and padding, so:\n",
    "\n",
    "```python\n",
    "conv1 = tf.layers.conv2d(\n",
    "    inputs=input_layer,\n",
    "    filters=32,\n",
    "    kernel_size=[5, 5],\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `conv1` output size\n",
    "\n",
    "we use `same` padding, so the height and width dimensions of the output shape don't change. all that changes is the channel dimension, and our input shape is `[-1, 28, 28, 32]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we use `same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pooling layer #1\n",
    "\n",
    "here we take the convolution and max pool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.layers.max_pooling2d?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we are going to do a 2x2 pool with a stride of 2 and *valid* padding (that is, pool only over \"valid\" values, don't create artifical 0 values around the boundary. yes, the naming convention is awful and stupid): \n",
    "\n",
    "```python\n",
    "pool1 = tf.layers.max_pooling2d(\n",
    "    inputs=conv1,\n",
    "    pool_size=[2, 2],\n",
    "    strides=2,\n",
    "    #padding='valid' is implicit\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `pool1` output size\n",
    "\n",
    "because we use `valid` padding instead of `same` and because we have a stride of 2, our new tensor size post-pooling is `{height,width} / padding`. the number of channels is fixed, so the new output size is `[-1, 14, 14, 32]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convolutional layer #2 and pooling layer #2\n",
    "\n",
    "we repeat the process on this transformed tensor, but this time we double the number of filters to 64\n",
    "\n",
    "```python\n",
    "conv2 = tf.layers.conv2d(\n",
    "    inputs=pool1,\n",
    "    filters=64,\n",
    "    kernel_size=[5, 5],\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu\n",
    ")\n",
    "\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `conv2` and `pool2` output size\n",
    "\n",
    "for the convolution layer, we again use `same` padding, so the height and width sizes are fixe. the number of filters increases to 64, so the output tensor of `conv2` has size `[-1, 14, 14, 64]`.\n",
    "\n",
    "for the pool layer, everything is the same -- `stride=2` halves the height and width sizes and our output from the `pool2` layer is `[-1, 7, 7, 64]`. that is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3136"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7 * 7 * 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "elements per record in a batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dense layer\n",
    "\n",
    "the steps above have \"built features\"\n",
    "\n",
    "**note**: this is a pet peeve of mine. it's often stated thus as if what *follows* is *not* further feature engineering. what you have are complicated features that you could interpret as still being images, and can mentally relate to the input images. that's not a feature any more than `[1.3436147, -473.147387, ...]` is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we go through the normal deep neural shit. start by flattening to `batch_size, x_size`: `[-1, 7 * 7 * 64]`:\n",
    "\n",
    "```python\n",
    "pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then passign that into a 1024 unit `dense` layer:\n",
    "\n",
    "```python\n",
    "dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for generalizability, we include a dropout layer. everything I've ever seen suggests a dropout value of 0.5, but I guess we know better and use 0.4\n",
    "\n",
    "```python\n",
    "dropout = tf.layers.dropout(\n",
    "    inputs=dense,\n",
    "    rate=0.4,\n",
    "    training=mode == tf.estimator.ModeKeys.TRAIN\n",
    ")\n",
    "```\n",
    "\n",
    "the `training` argument is actually super helpful, because it handles the control flow logic of applying random dropout during *training* (when we want it, to promote generalizability) but **not** during evaluation or testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `dense` and `dropout` layers ouptut size\n",
    "\n",
    "final size: `[-1, 1024]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logits layer\n",
    "\n",
    "finally, given those 1024 features, make a prediction for each of the 10 classes\n",
    "\n",
    "```python\n",
    "logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `logits` output size\n",
    "\n",
    "`[-1, 10]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate predictions\n",
    "\n",
    "the `logits` values are individual prediction probabilities for each class. take the highest among them with `tf.argmax` and `tf.nn.softmax` to develop overall predictions and prediction probabilities\n",
    "\n",
    "```python\n",
    "predictions = {\n",
    "    \"classes\": tf.argmax(input=logits, axis=1),\n",
    "    \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if the model was invoked in the `PREDICT` mode, we're done -- just return what we've built above\n",
    "\n",
    "```python\n",
    "if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "  return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate loss\n",
    "\n",
    "if the model was invoked in either the `EVAL` or `TRAIN` mode, then we will need to be able to return the `loss` for the current weights, biases, hyperparmaeters (etc). this is a multi-class prediciton problem, so the natural choice is crossentropy:\n",
    "\n",
    "```python\n",
    "onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10)\n",
    "loss = tf.losses.softmax_cross_entropy(\n",
    "    onehot_labels=onehot_labels, logits=logits\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our labels is a `[batch_size]` shaped tensor of integers, whereas our `logits` is `[batch_size, number_of_labels]` shaped. this is the motivation for converting the labels into one-hot tensors. below is a quick diversion into just what that looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stupidest labels\n",
    "labels = list(range(10)) + list(range(10))\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "utils.inspect(tf.cast(labels, tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'one_hot_labels:0' shape=(20, 10) dtype=float32>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10, name='one_hot_labels')\n",
    "onehot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "utils.inspect(onehot_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*note*: this is easy because the labels are already 0 - 9. if they had been values, we would have had to do some bullshit. not sure how we would have done that tbh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, suppose we had managed to make `logits` predictions that were always mostly right but just enough wrong:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = onehot_labels * .9 + .01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.90999997 0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.90999997 0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.90999997 0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.90999997 0.01       0.01\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.90999997 0.01\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.01       0.90999997\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.90999997 0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.90999997 0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.90999997 0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.90999997]\n",
      " [0.90999997 0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.90999997 0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.90999997 0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.90999997 0.01       0.01\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.90999997 0.01\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.01       0.90999997\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.90999997 0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.90999997 0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.90999997 0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.90999997]]\n"
     ]
    }
   ],
   "source": [
    "utils.inspect(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then the loss is the crossentropy loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'softmax_cross_entropy_loss_1/value:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = tf.losses.softmax_cross_entropy(\n",
    "    onehot_labels=onehot_labels,\n",
    "    logits=logits\n",
    ")\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5388281\n"
     ]
    }
   ],
   "source": [
    "utils.inspect(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### configure the training op\n",
    "\n",
    "one valid mode is `tf.estimator.ModeKeys.TRAIN`. if we are meant to train, we should create a training operation. there are a bunch of ways to do this, and one is:\n",
    "\n",
    "```python\n",
    "if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step()\n",
    "    )\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add evaluation metrics\n",
    "\n",
    "if we haven't already exited, we must be in the `tf.estimator.ModeKeys.EVAL` mode.\n",
    "\n",
    "we *could* be done at this point, but we're greedy. when we evaluate, we decide to actually evaluate *something*, so we choose to calculate the accuracy of our predictions. we could have calculated a ton of stuff. for a sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'auc',\n",
       " 'average_precision_at_k',\n",
       " 'false_negatives',\n",
       " 'false_negatives_at_thresholds',\n",
       " 'false_positives',\n",
       " 'false_positives_at_thresholds',\n",
       " 'mean',\n",
       " 'mean_absolute_error',\n",
       " 'mean_cosine_distance',\n",
       " 'mean_iou',\n",
       " 'mean_per_class_accuracy',\n",
       " 'mean_relative_error',\n",
       " 'mean_squared_error',\n",
       " 'mean_tensor',\n",
       " 'percentage_below',\n",
       " 'precision',\n",
       " 'precision_at_k',\n",
       " 'precision_at_thresholds',\n",
       " 'precision_at_top_k',\n",
       " 'recall',\n",
       " 'recall_at_k',\n",
       " 'recall_at_thresholds',\n",
       " 'recall_at_top_k',\n",
       " 'root_mean_squared_error',\n",
       " 'sensitivity_at_specificity',\n",
       " 'sparse_average_precision_at_k',\n",
       " 'sparse_precision_at_k',\n",
       " 'specificity_at_sensitivity',\n",
       " 'true_negatives',\n",
       " 'true_negatives_at_thresholds',\n",
       " 'true_positives',\n",
       " 'true_positives_at_thresholds']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[_ for _ in dir(tf.metrics) if not _[0] == '_']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the `EVAL` mode supports calculation of various metric operations, so we push our accuracy calcualtion in as an eval metric operation:\n",
    "\n",
    "```python\n",
    "eval_metric_ops = {\n",
    "    \"accuracy\": tf.metrics.accuracy(\n",
    "        labels=labels, predictions=predictions[\"classes\"]\n",
    "    )\n",
    "}\n",
    "\n",
    "return tf.estimator.EstimatorSpec(\n",
    "    mode=mode,\n",
    "    loss=loss,\n",
    "    eval_metric_ops=eval_metric_ops\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training and evaluating the cnn mnist classifier\n",
    "\n",
    "the model is defined. dope. not dope enough, though. let's put all of what we need to do into a glorious `main` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load training and test data\n",
    "\n",
    "go get the data. here we are hacking things a bit by using the `load_dataset` for mnist. we shouldn't do this. oh well.\n",
    "\n",
    "within the `main` function (first 5 lines), go get the data and unpack it into more useful separate feature tensors\n",
    "\n",
    "```python\n",
    "# Load training and eval data\n",
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "train_data = mnist.train.images # Returns np.array\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "eval_data = mnist.test.images # Returns np.array\n",
    "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create the estimator\n",
    "\n",
    "next steps in `main`: creating a `tf.estimator.Estimator` object implementing the `cnn_model_fn` we defined above\n",
    "\n",
    "```python\n",
    "mnist_classifier = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model_fn,\n",
    "    model_dir='/tmp/mnist_convnet_model'\n",
    ")\n",
    "```\n",
    "\n",
    "if you are running this within a `docker` container and want to access the model checkpoint information (you probably do), consider moving that `model_dir` value to a different location accessible from the base container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up a logging hook\n",
    "\n",
    "logging is cool, right?\n",
    "\n",
    "```python\n",
    "# Set up logging for predictions\n",
    "tensors_to_log = {\n",
    "    # [printed label name]: [tensor name in graph]\n",
    "    \"probabilities\": \"softmax_tensor\"\n",
    "}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "    tensors=tensors_to_log,\n",
    "    every_n_iter=50\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is an alternative to creating explicit summary ops and looking at the summaries via `tensorflow`. in *this* instance, we will actually print the given tensor to the logs (so you will see this in the running logs for the cli). I prefer the tensorboard method only for eventual usability, but this is something I intend to add in the future as well.\n",
    "\n",
    "for what it's worth, there is an `every_n_secs` option if you dont' care for fixed iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.train.LoggingTensorHook?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train the model\n",
    "\n",
    "we have data loaded into the scope of `main`, and we have an estimator that can train on features of that general shape. what remains is to connect the two -- this is done by defining an `input_fn` for ingesting the features and generating `features, labels` pairs (as expected inputs to the `model_fn`). this is a common use case, so a canned version of this function already exists for us:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_data},\n",
    "    y=train_labels,\n",
    "    batch_size=100,\n",
    "    num_epochs=None,\n",
    "    shuffle=True\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "having defined that input function, we simply pass it to the `train` method of the estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.estimator.Estimator.train?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "mnist_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=20000,\n",
    "    hooks=[logging_hook]\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this will run until the number of steps has been exhausted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate the model\n",
    "\n",
    "after training, we have a separate test set we can use to evaluate the performance of our trained model on out-of-sample records. just like with training above, we do this by connecting the ingested `numpy` arrays of test data with the estimator using a evaluation `input_fn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Evaluate the model and print results\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": eval_data},\n",
    "    y=eval_labels,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and this is evaluated by the estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.estimator.Estimator.evaluate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run the model\n",
    "\n",
    "it is not explained *at all*, but for some reason the function `tf.app.run()` seems to create a session context and execute the `main` function. I am not in any way *declaring* that we should use `main`, so that's odd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.app.run??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "invocation is done from the shell via `python cnn_mnist.py`. execute that in a neighboring terminal\n",
    "\n",
    "*note*: on the gpu machine with *no* gpu access but little competition for cpu resources, this took several (closer to 30 than 0) minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the final output I received was\n",
    "\n",
    "```\n",
    "INFO:tensorflow:Loss for final step: 0.13426968.\n",
    "INFO:tensorflow:Calling model_fn.\n",
    "INFO:tensorflow:Done calling model_fn.\n",
    "INFO:tensorflow:Starting evaluation at 2018-07-10-18:44:57\n",
    "INFO:tensorflow:Graph was finalized.\n",
    "INFO:tensorflow:Restoring parameters from /home/zlamberty/tmp/mnist_convnet_model/model.ckpt-20000\n",
    "INFO:tensorflow:Running local_init_op.\n",
    "INFO:tensorflow:Done running local_init_op.\n",
    "INFO:tensorflow:Finished evaluation at 2018-07-10-18:45:00\n",
    "INFO:tensorflow:Saving dict for global step 20000: accuracy = 0.9705, global_step = 20000, loss = 0.09808666\n",
    "{'accuracy': 0.9705, 'loss': 0.09808666, 'global_step': 20000}\n",
    "zlamberty@b715efb0d2d6:~/notebooks/deep_learning_world_tour/tens\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## additional resources\n",
    "\n",
    "links to other tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summary\n",
    "\n",
    "this was a pretty good tutorial on the basic structure of a `tensorflow` program using the `tf.layers` and `tf.estimator` apis. all told, our script has a little over 200 lines of code and runs in about a half an hour to achieve an accuracy of 97.3% with no hyperparameter tuning (not bad!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the general program flow was implemented again:\n",
    "\n",
    "1. define some way of ignesting data (preferably with `tf.data.Dataset` `api`, not done that way here)\n",
    "1. define a model via a `model_fn` function\n",
    "    1. should support `tf.estimator.ModeKeys.{TRAIN,EVAL,PREDICT}`\n",
    "1. define a way of stitching the above two together (an `input_fn`)\n",
    "    1. usually separate functions are provided for `TRAIN` and `EVAL`\n",
    "1. create an instance of the model and invoke the desired modes\n",
    "    1. `estimator.train(...)`\n",
    "    1. `estimator.eval(...)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

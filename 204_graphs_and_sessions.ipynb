{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# graphs and sessions\n",
    "\n",
    "following along with [this page](https://www.tensorflow.org/programmers_guide/graphs)\n",
    "\n",
    "the general idea is that a `tensorflow` computation is defined as a dag (the `tf.Graph`) and executed within a computation environment called a session (the `tf.Session`)\n",
    "\n",
    "I'm not yet sure how this will differ content-wise from the number of other introductions we've already encountered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## why dataflow graphs?\n",
    "\n",
    "\"dataflow graphs\" are the names this document uses to describe the dag that everywhere else is referred to as a graph or computation graph. they provide the following example image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](https://www.tensorflow.org/images/tensors_flowing.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the author describes [*dataflow*](https://en.wikipedia.org/wiki/Dataflow_programming) as \"a common programming model for parallel computing.\" here they describe the nodes as \"units of computation\" and the edges as the \"data consumed or produced by a computation.\"\n",
    "\n",
    "the example: the `tf.matmul` is an operation (a node) which has two inpcoming edges (the matrices being multiplied) and one outgoing edge (the output of the matrix multiplication calculation).\n",
    "\n",
    "the listed advantages:\n",
    "\n",
    "1. parallelism\n",
    "1. distributed execution\n",
    "1. compilation\n",
    "1. portability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## what is a `tf.Graph`?\n",
    "\n",
    "the graph is basically two things:\n",
    "\n",
    "1. graph structure: nodes and edges\n",
    "1. graph collections: metadata information grouped into categories / collections\n",
    "\n",
    "this section is *not* helpful. the distinction between the above is not at all clear, and they really only toss out there that \"nodes and edges\" are not the computation. the analogy is \"assembly code\", suggesting it \"does not contain all of the userful context the source code conveys\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## building a `tf.Graph`\n",
    "\n",
    "first stage of a tensorflow project: building the `tf.Graph`. tensorflow itself provides a *default graph* that all api functions take as an implicit input (okay, this is good to know). discussion on having more than one graph is at the end of this page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the example are pretty good and worth reading so I'll reproduce them exactly here. I like the way they break it down into the `tf.Operation` and `tf.Tensor` objects that are being created under the hood:\n",
    "\n",
    "> + Calling `tf.constant(42.0)` creates a single `tf.Operation` that produces the value 42.0, adds it to the default graph, and returns a `tf.Tensor` that represents the value of the constant.\n",
    "> + Calling `tf.matmul(x, y)` creates a single `tf.Operation` that multiplies the values of `tf.Tensor` objects `x` and `y`, adds it to the default graph, and returns a `tf.Tensor` that represents the result of the multiplication.\n",
    "> + Executing `v = tf.Variable(0)` adds to the graph a `tf.Operation` that will store a writeable tensor value that persists between `tf.Session.run` calls. The `tf.Variable` object wraps this operation, and can be used like a tensor, which will read the current value of the stored value. The `tf.Variable` object also has methods such as `assign` and `assign_add` that create `tf.Operation` objects that, when executed, update the stored value. (See Variables for more information about variables.)\n",
    "> + Calling `tf.train.Optimizer.minimize` will add operations and tensors to the default graph that calculate gradients, and return a `tf.Operation` that, when run, will apply those gradients to a set of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(10)\n",
    "y = tf.Variable(0)\n",
    "z = tf.multiply(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/zlamberty/notebooks/deep_learning_world_tour/tensorflow_tutorial/utils.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:800px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.24695935282360515&quot;).pbtxt = 'node {\\n  name: &quot;Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 10\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/initial/value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Variable&quot;\\n  input: &quot;Variable/initial/value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Variable/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Variable&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Const&quot;\\n  input: &quot;Variable/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Assign/value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 5\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Variable&quot;\\n  input: &quot;Assign/value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Assign/1/value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 5\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Assign/1&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Variable&quot;\\n  input: &quot;Assign/1/value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Assign/2/value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 5\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Assign/2&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Variable&quot;\\n  input: &quot;Assign/2/value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.24695935282360515&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    y.assign(5)\n",
    "    graph_def = z.graph.as_graph_def()\n",
    "    tmp_def = utils.rename_nodes(graph_def, lambda s: \"/\".join(s.split('_', 1)))\n",
    "    utils.show_graph(tmp_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## naming operations\n",
    "\n",
    "all `tf.Operation` or `tf.Tensor` objects in a `tf.Graph` are put into namespaces. tensorflow automatically creates unique names in the root namespace for any operation that is not named explicitly, but explicit names cary the obvious readability / maintainability benefits.\n",
    "\n",
    "ways to name:\n",
    "\n",
    "+ hand-crafted names can be provided to all objects and tensors via the `name` parameter.\n",
    "+ name scope prefixes can be added with `tf.name_scope` context managers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_0 = tf.constant(0, name=\"c\")  # => operation named \"c\"\n",
    "\n",
    "# Already-used names will be \"uniquified\".\n",
    "c_1 = tf.constant(2, name=\"c\")  # => operation named \"c_1\"\n",
    "\n",
    "# Name scopes add a prefix to all operations created in the same context.\n",
    "with tf.name_scope(\"outer\"):\n",
    "    c_2 = tf.constant(2, name=\"c\")  # => operation named \"outer/c\"\n",
    "  \n",
    "    # Name scopes nest like paths in a hierarchical file system.\n",
    "    with tf.name_scope(\"inner\"):\n",
    "        c_3 = tf.constant(3, name=\"c\")  # => operation named \"outer/inner/c\"\n",
    "  \n",
    "    # Exiting a name scope context will return to the previous prefix.\n",
    "    c_4 = tf.constant(4, name=\"c\")  # => operation named \"outer/c_1\"\n",
    "  \n",
    "    # Already-used name scopes will be \"uniquified\".\n",
    "    with tf.name_scope(\"inner\"):\n",
    "        c_5 = tf.constant(5, name=\"c\")  # => operation named \"outer/inner_1/c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:0',\n",
       " 'c_1:0',\n",
       " 'outer/c:0',\n",
       " 'outer/inner/c:0',\n",
       " 'outer/c_1:0',\n",
       " 'outer/inner_1/c:0']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[_.name for _ in [c_0, c_1, c_2, c_3, c_4, c_5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## placing operations on different devices\n",
    "\n",
    "we've covered this about a million times, but there is actually new info here. first, the repeat info: instruct a specific graph calculation to occur on a specific device with the `tf.device` context manager.\n",
    "\n",
    "the defice specification has the format\n",
    "\n",
    "```python\n",
    "'/job:{job_name}/task:{task_index}/device:{device_type}:{device_index}'\n",
    "```\n",
    "\n",
    "+ `job_name` is an alpha-numeric string that doesn't start with a number\n",
    "+ `task_index` is a non-negative integer indexing tasks within a fixed `job_name`\n",
    "+ `device_type` is `gpu`, `cpu`, `tpu`, etc\n",
    "+ `device_index` is a non-negative integer indexing devices within a type category `device_type`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here's an example program for distributing computation utilizing both a gpu and cpu (more specifically, this utilizes either gpu or cpu unless otherwise specified, but *requires* cpu or gpu usage where listed explicitly):\n",
    "\n",
    "```python\n",
    "# Operations created outside either context will run on the \"best possible\"\n",
    "# device. For example, if you have a GPU and a CPU available, and the operation\n",
    "# has a GPU implementation, TensorFlow will choose the GPU.\n",
    "weights = tf.random_normal(...)\n",
    "\n",
    "with tf.device(\"/device:CPU:0\"):\n",
    "  # Operations created in this context will be pinned to the CPU.\n",
    "  img = tf.decode_jpeg(tf.read_file(\"img.jpg\"))\n",
    "\n",
    "with tf.device(\"/device:GPU:0\"):\n",
    "  # Operations created in this context will be pinned to the GPU.\n",
    "  result = tf.matmul(weights, img)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and here, another example where we have a distributed setup with a parameter sever job (`/job:ps`) and a worker job (`/job:worker`)\n",
    "\n",
    "```python\n",
    "with tf.device(\"/job:ps/task:0\"):\n",
    "    weights_1 = tf.Variable(tf.truncated_normal([784, 100]))\n",
    "    biases_1 = tf.Variable(tf.zeroes([100]))\n",
    "\n",
    "with tf.device(\"/job:ps/task:1\"):\n",
    "    weights_2 = tf.Variable(tf.truncated_normal([100, 10]))\n",
    "    biases_2 = tf.Variable(tf.zeroes([10]))\n",
    "\n",
    "with tf.device(\"/job:worker\"):\n",
    "    layer_1 = tf.matmul(train_batch, weights_1) + biases_1\n",
    "    layer_2 = tf.matmul(train_batch, weights_2) + biases_2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "general heuristic the author recommends: use `tf.train.replica_device_setter` in conjunction with `tf.device` for distributed computing:\n",
    "\n",
    "```python\n",
    "with tf.device(tf.train.replica_device_setter(ps_tasks=3)):\n",
    "    # tf.Variable objects are, by default, placed on tasks in \"/job:ps\" in a\n",
    "    # round-robin fashion.\n",
    "    w_0 = tf.Variable(...)  # placed on \"/job:ps/task:0\"\n",
    "    b_0 = tf.Variable(...)  # placed on \"/job:ps/task:1\"\n",
    "    w_1 = tf.Variable(...)  # placed on \"/job:ps/task:2\"\n",
    "    b_1 = tf.Variable(...)  # placed on \"/job:ps/task:0\"\n",
    "  \n",
    "    input_data = tf.placeholder(tf.float32)     # placed on \"/job:worker\"\n",
    "    layer_0 = tf.matmul(input_data, w_0) + b_0  # placed on \"/job:worker\"\n",
    "    layer_1 = tf.matmul(layer_0, w_1) + b_1     # placed on \"/job:worker\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensor-like objects\n",
    "\n",
    "there are some things that are not tensor that can be cast to tensors. they call this \"tensor-like\". the objecdts they list are:\n",
    "\n",
    "+ `tf.Tensor`\n",
    "+ `tf.Variable`\n",
    "+ `numpy.ndarray`\n",
    "+ `list`\n",
    "+ any scalar `python` builtin type\n",
    "\n",
    "if I have something special I want to make \"tensor-like\" I can register a conversion method using `tf.register_tensor_conversion_function`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## executing a graph in a `tf.Session`\n",
    "\n",
    "the `tf.Session` object manages a connection between the \"client\" program (`python`) and the `c++` runtime. it handles distirbution, caching, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating a `tf.Session`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we've done this about a million times now:\n",
    "\n",
    "```python\n",
    "with tf.Session() as sess:\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remotely, the protocol is [`grpc`](https://grpc.io/), so you can make remote connections to tensorflow sessions using:\n",
    "\n",
    "```python\n",
    "with tf.Session('grps://{hostname}:{port}'):\n",
    "    ...\n",
    "```\n",
    "\n",
    "in the documentation the example port is 2222, so that is possibly a tensorflow default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there is a note added that higher-level apis will often handle sessions for you, so to parameterize them you must utilize provided `target` or `config` arguments instead of the low-level arguments to `tf.Session`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.Session.__init__?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "constructor arguments:\n",
    "\n",
    "+ `target`: the location of the execution engine. default is localhost device\n",
    "+ `graph`: optional explicit graph argument. default behavior is default session graph\n",
    "+ `config`: this is a `ConfigProto` object, a protobuffer configuring the running of the current session\n",
    "    + some options:\n",
    "        + `graph_options.optimizer_options`: hard-coded options for the optimizer operations\n",
    "        + `gpu_options.allow_growth`: rather than allocate most GPU memory at startup, allow it to grow as memory is required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using `tf.Session.run` to execute operations\n",
    "\n",
    "the input to a `tf.Session.run` call is a list of *fetches*, tensor-like objects for which you would like the computation to be performed. this determines a *subgraph* of the overall session graph that must be calculated (it will be lazy and avoid calculating anything not on the critical path).\n",
    "\n",
    "here is their provided example demonstrating how different arguments lead to different subgraphs being calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 37. -23.]\n",
      " [  1.   4.]]\n",
      "[[1.0000000e+00 6.7093851e-11]\n",
      " [5.4350060e-01 4.5649943e-01]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[37.0, -23.0], [1.0, 4.0]])\n",
    "w = tf.Variable(tf.random_uniform([2, 2]))\n",
    "y = tf.matmul(x, w)\n",
    "output = tf.nn.softmax(y)\n",
    "init_op = w.initializer\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Run the initializer on `w`.\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    # evaluate just x -- won't calculate y or output\n",
    "    print(sess.run(x))\n",
    "    \n",
    "    # Evaluate `output`. `sess.run(output)` will return a NumPy array containing\n",
    "    # the result of the computation.\n",
    "    print(sess.run(output))\n",
    "    \n",
    "    # Evaluate `y` and `output`. Note that `y` will only be computed once, and its\n",
    "    # result used both to return `y_val` and as an input to the `tf.nn.softmax()`\n",
    "    # op. Both `y_val` and `output_val` will be NumPy arrays.\n",
    "    y_val, output_val = sess.run([y, output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameterization also comes to individual `tf.Session` objects through the `feed_dict` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 4. 9.]\n",
      "[ 0.  0. 25.]\n",
      "told ya so!\n",
      "told ya so!\n"
     ]
    }
   ],
   "source": [
    "# Define a placeholder that expects a vector of three floating-point values,\n",
    "# and a computation that depends on it.\n",
    "x = tf.placeholder(tf.float32, shape=[3])\n",
    "y = tf.square(x)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Feeding a value changes the result that is returned when you evaluate `y`.\n",
    "    print(sess.run(y, {x: [1.0, 2.0, 3.0]}))  # => \"[1.0, 4.0, 9.0]\"\n",
    "    print(sess.run(y, {x: [0.0, 0.0, 5.0]}))  # => \"[0.0, 0.0, 25.0]\"\n",
    "  \n",
    "    # Raises <a href=\"../api_docs/python/tf/errors/InvalidArgumentError\"><code>tf.errors.InvalidArgumentError</code></a>, because you must feed a value for\n",
    "    # a `tf.placeholder()` when evaluating a tensor that depends on it.\n",
    "    try:\n",
    "        sess.run(y)\n",
    "    except tf.errors.InvalidArgumentError:\n",
    "        print('told ya so!')\n",
    "  \n",
    "    # Raises `ValueError`, because the shape of `37.0` does not match the shape\n",
    "    # of placeholder `x`.\n",
    "    try:\n",
    "        sess.run(y, {x: 37.0})\n",
    "    except ValueError:\n",
    "        print('told ya so!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one last example, this time demonstrating how to use the `options` and `run_metadata` arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[node {\n",
      "  name: \"MatMul_11/a\"\n",
      "  op: \"Const\"\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        tensor_content: \"\\000\\000\\024B\\000\\000\\270\\301\\000\\000\\200?\\000\\000\\200@\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"random_uniform_11/shape\"\n",
      "  op: \"Const\"\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        tensor_content: \"\\002\\000\\000\\000\\002\\000\\000\\000\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"random_uniform_11/RandomUniform\"\n",
      "  op: \"RandomUniform\"\n",
      "  input: \"random_uniform_11/shape\"\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"seed\"\n",
      "    value {\n",
      "      i: 0\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"seed2\"\n",
      "    value {\n",
      "      i: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"random_uniform_11/mul\"\n",
      "  op: \"Snapshot\"\n",
      "  input: \"random_uniform_11/RandomUniform\"\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"random_uniform_11\"\n",
      "  op: \"Snapshot\"\n",
      "  input: \"random_uniform_11/mul\"\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"MatMul_11\"\n",
      "  op: \"MatMul\"\n",
      "  input: \"MatMul_11/a\"\n",
      "  input: \"random_uniform_11\"\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"transpose_a\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"transpose_b\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"_retval_MatMul_11_0_0\"\n",
      "  op: \"_Retval\"\n",
      "  input: \"MatMul_11\"\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"index\"\n",
      "    value {\n",
      "      i: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "library {\n",
      "}\n",
      "versions {\n",
      "  producer: 26\n",
      "}\n",
      "]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "dev_stats {\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  node_stats {\n",
      "    node_name: \"_SOURCE\"\n",
      "    all_start_micros: 1530630288427269\n",
      "    op_start_rel_micros: 5\n",
      "    op_end_rel_micros: 9\n",
      "    all_end_rel_micros: 17\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "    }\n",
      "    timeline_label: \"_SOURCE = NoOp()\"\n",
      "    scheduled_micros: 1530630288427206\n",
      "    memory_stats {\n",
      "    }\n",
      "  }\n",
      "  node_stats {\n",
      "    node_name: \"MatMul_11/a\"\n",
      "    all_start_micros: 1530630288427293\n",
      "    op_start_rel_micros: 1\n",
      "    op_end_rel_micros: 11\n",
      "    all_end_rel_micros: 16\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "    }\n",
      "    output {\n",
      "      tensor_description {\n",
      "        dtype: DT_FLOAT\n",
      "        shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        allocation_description {\n",
      "          requested_bytes: 16\n",
      "          allocator_name: \"cpu\"\n",
      "          ptr: 140493348458880\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    timeline_label: \"MatMul_11/a = Const()\"\n",
      "    scheduled_micros: 1530630288427286\n",
      "    memory_stats {\n",
      "      persistent_memory_size: 16\n",
      "    }\n",
      "  }\n",
      "  node_stats {\n",
      "    node_name: \"random_uniform_11/shape\"\n",
      "    all_start_micros: 1530630288427311\n",
      "    op_start_rel_micros: 1\n",
      "    op_end_rel_micros: 4\n",
      "    all_end_rel_micros: 7\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "    }\n",
      "    output {\n",
      "      tensor_description {\n",
      "        dtype: DT_INT32\n",
      "        shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        allocation_description {\n",
      "          requested_bytes: 8\n",
      "          allocator_name: \"cpu\"\n",
      "          ptr: 140493348458912\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    timeline_label: \"random_uniform_11/shape = Const()\"\n",
      "    scheduled_micros: 1530630288427309\n",
      "    memory_stats {\n",
      "      persistent_memory_size: 8\n",
      "    }\n",
      "  }\n",
      "  node_stats {\n",
      "    node_name: \"random_uniform_11/RandomUniform\"\n",
      "    all_start_micros: 1530630288427320\n",
      "    op_start_rel_micros: 2\n",
      "    op_end_rel_micros: 17\n",
      "    all_end_rel_micros: 21\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "      total_bytes: 16\n",
      "      peak_bytes: 16\n",
      "      live_bytes: 16\n",
      "      allocation_records {\n",
      "        alloc_micros: 1530630288427331\n",
      "        alloc_bytes: 16\n",
      "      }\n",
      "      allocation_records {\n",
      "        alloc_micros: 1530630288427375\n",
      "        alloc_bytes: -16\n",
      "      }\n",
      "    }\n",
      "    output {\n",
      "      tensor_description {\n",
      "        dtype: DT_FLOAT\n",
      "        shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        allocation_description {\n",
      "          requested_bytes: 16\n",
      "          allocated_bytes: 16\n",
      "          allocator_name: \"cpu\"\n",
      "          allocation_id: 1\n",
      "          has_single_reference: true\n",
      "          ptr: 140493082120256\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    timeline_label: \"random_uniform_11/RandomUniform = RandomUniform(random_uniform_11/shape)\"\n",
      "    scheduled_micros: 1530630288427318\n",
      "    memory_stats {\n",
      "    }\n",
      "  }\n",
      "  node_stats {\n",
      "    node_name: \"random_uniform_11/mul\"\n",
      "    all_start_micros: 1530630288427344\n",
      "    op_end_rel_micros: 3\n",
      "    all_end_rel_micros: 6\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "    }\n",
      "    output {\n",
      "      tensor_description {\n",
      "        dtype: DT_FLOAT\n",
      "        shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        allocation_description {\n",
      "          requested_bytes: 16\n",
      "          allocated_bytes: 16\n",
      "          allocator_name: \"cpu\"\n",
      "          allocation_id: 1\n",
      "          ptr: 140493082120256\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    timeline_label: \"random_uniform_11/mul = Snapshot(random_uniform_11/RandomUniform)\"\n",
      "    scheduled_micros: 1530630288427341\n",
      "    memory_stats {\n",
      "    }\n",
      "  }\n",
      "  node_stats {\n",
      "    node_name: \"random_uniform_11\"\n",
      "    all_start_micros: 1530630288427353\n",
      "    op_start_rel_micros: 1\n",
      "    op_end_rel_micros: 2\n",
      "    all_end_rel_micros: 5\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "    }\n",
      "    output {\n",
      "      tensor_description {\n",
      "        dtype: DT_FLOAT\n",
      "        shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        allocation_description {\n",
      "          requested_bytes: 16\n",
      "          allocated_bytes: 16\n",
      "          allocator_name: \"cpu\"\n",
      "          allocation_id: 1\n",
      "          ptr: 140493082120256\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    timeline_label: \"random_uniform_11 = Snapshot(random_uniform_11/mul)\"\n",
      "    scheduled_micros: 1530630288427350\n",
      "    memory_stats {\n",
      "    }\n",
      "  }\n",
      "  node_stats {\n",
      "    node_name: \"MatMul_11\"\n",
      "    all_start_micros: 1530630288427361\n",
      "    op_end_rel_micros: 10\n",
      "    all_end_rel_micros: 16\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "      total_bytes: 16\n",
      "      peak_bytes: 16\n",
      "      live_bytes: 16\n",
      "      allocation_records {\n",
      "        alloc_micros: 1530630288427364\n",
      "        alloc_bytes: 16\n",
      "      }\n",
      "    }\n",
      "    output {\n",
      "      tensor_description {\n",
      "        dtype: DT_FLOAT\n",
      "        shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        allocation_description {\n",
      "          requested_bytes: 16\n",
      "          allocated_bytes: 16\n",
      "          allocator_name: \"cpu\"\n",
      "          allocation_id: 1\n",
      "          has_single_reference: true\n",
      "          ptr: 140493082120416\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    timeline_label: \"MatMul_11 = MatMul(MatMul_11/a, random_uniform_11)\"\n",
      "    scheduled_micros: 1530630288427358\n",
      "    memory_stats {\n",
      "    }\n",
      "  }\n",
      "  node_stats {\n",
      "    node_name: \"_retval_MatMul_11_0_0\"\n",
      "    all_start_micros: 1530630288427380\n",
      "    op_start_rel_micros: 1\n",
      "    op_end_rel_micros: 2\n",
      "    all_end_rel_micros: 6\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "    }\n",
      "    timeline_label: \"_retval_MatMul_11_0_0 = _Retval(MatMul_11)\"\n",
      "    scheduled_micros: 1530630288427377\n",
      "    memory_stats {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = tf.matmul([[37.0, -23.0], [1.0, 4.0]], tf.random_uniform([2, 2]))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Define options for the `sess.run()` call.\n",
    "    options = tf.RunOptions()\n",
    "    options.output_partition_graphs = True\n",
    "    options.trace_level = tf.RunOptions.FULL_TRACE\n",
    "  \n",
    "    # Define a container for the returned metadata.\n",
    "    metadata = tf.RunMetadata()\n",
    "  \n",
    "    sess.run(y, options=options, run_metadata=metadata)\n",
    "  \n",
    "    # Print the subgraphs that executed on each device.\n",
    "    print(metadata.partition_graphs)\n",
    "  \n",
    "    print('\\n{:-^100}\\n'.format(''))\n",
    "    \n",
    "    # Print the timings of each operation that executed.\n",
    "    print(metadata.step_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.RunOptions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ByteSize',\n",
       " 'Clear',\n",
       " 'ClearExtension',\n",
       " 'ClearField',\n",
       " 'CopyFrom',\n",
       " 'DEBUG_OPTIONS_FIELD_NUMBER',\n",
       " 'DESCRIPTOR',\n",
       " 'DiscardUnknownFields',\n",
       " 'Extensions',\n",
       " 'FULL_TRACE',\n",
       " 'FindInitializationErrors',\n",
       " 'FromString',\n",
       " 'HARDWARE_TRACE',\n",
       " 'HasExtension',\n",
       " 'HasField',\n",
       " 'INTER_OP_THREAD_POOL_FIELD_NUMBER',\n",
       " 'IsInitialized',\n",
       " 'ListFields',\n",
       " 'MergeFrom',\n",
       " 'MergeFromString',\n",
       " 'NO_TRACE',\n",
       " 'OUTPUT_PARTITION_GRAPHS_FIELD_NUMBER',\n",
       " 'ParseFromString',\n",
       " 'REPORT_TENSOR_ALLOCATIONS_UPON_OOM_FIELD_NUMBER',\n",
       " 'RegisterExtension',\n",
       " 'SOFTWARE_TRACE',\n",
       " 'SerializePartialToString',\n",
       " 'SerializeToString',\n",
       " 'SetInParent',\n",
       " 'TIMEOUT_IN_MS_FIELD_NUMBER',\n",
       " 'TRACE_LEVEL_FIELD_NUMBER',\n",
       " 'TraceLevel',\n",
       " 'WhichOneof',\n",
       " '_CheckCalledFromGeneratedFile',\n",
       " '_SetListener',\n",
       " '_extensions_by_name',\n",
       " '_extensions_by_number',\n",
       " '_tf_api_names']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[_ for _ in dir(options) if not _[:2] == '__']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualizing your graph\n",
    "\n",
    "the recommended tool for visualizing graphs is the *grpah visualizer*, a component of the tensorboard program. they recommend creating a `tf.summary.FileWriter` object and using that to write summary files to a monitored tensorboard directory in a way that tensorboard can turn into a graph.\n",
    "\n",
    "this has been hacked out and put into a single function in `utils`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/matplotlib/__init__.py\n",
      "/usr/local/lib/python3.5/dist-packages/pandas/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import pandas as pd\n",
    "\n",
    "print(matplotlib.__file__)\n",
    "print(pd.__file__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## programming with multiple graphs\n",
    "\n",
    "it is common that you will want to keep the training, evaluation, and prediction stages of your model highly separated. this could be done by using separate python processes, but it can *also* be done by using completely independent graphs.\n",
    "\n",
    "`tf.Graph` objects define independent namespaces for `tf.Operations` objects. within that namespace, all operations are \"uniquified\". if you have several unconnected computational graphs, consider creating separate `tf.Graph` objects and adding connected components to their own graph. this is organizationally better, but also reduces the overhead of storing everything in the default graph.\n",
    "\n",
    "finally, replace the default graph with the `tf.Graph.as_default` context manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.ops.Graph at 0x7fc6ad2ae160>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_1 = tf.Graph()\n",
    "g_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with g_1.as_default():\n",
    "    # Operations created in this scope will be added to `g_1`.\n",
    "    c = tf.constant(\"Node in g_1\")\n",
    "  \n",
    "    # Sessions created in this scope will run operations from `g_1`.\n",
    "    sess_1 = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.ops.Graph at 0x7fc6ad2ae320>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_2 = tf.Graph()\n",
    "g_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with g_2.as_default():\n",
    "    # Operations created in this scope will be added to `g_2`.\n",
    "    d = tf.constant(\"Node in g_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, you can pass a graph when constructing a <a href=\"../api_docs/python/tf/Session\"><code>tf.Session</code></a>:\n",
    "# `sess_2` will run operations from `g_2`.\n",
    "sess_2 = tf.Session(graph=g_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert c.graph is g_1\n",
    "assert sess_1.graph is g_1\n",
    "\n",
    "assert d.graph is g_2\n",
    "assert sess_2.graph is g_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'Const' type=Const>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_1.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'Const' type=Const>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_2.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Operation 'Const' type=Const>, <tf.Operation 'Variable/initial_value' type=Const>, <tf.Operation 'Variable' type=VariableV2>, <tf.Operation 'Variable/Assign' type=Assign>, <tf.Operation 'Variable/read' type=Identity>, <tf.Operation 'Mul' type=Mul>, <tf.Operation 'Assign/value' type=Const>, <tf.Operation 'Assign' type=Assign>, <tf.Operation 'c' type=Const>, <tf.Operation 'c_1' type=Const>, <tf.Operation 'outer/c' type=Const>, <tf.Operation 'outer/inner/c' type=Const>, <tf.Operation 'outer/c_1' type=Const>, <tf.Operation 'outer/inner_1/c' type=Const>, <tf.Operation 'Const_1' type=Const>, <tf.Operation 'random_uniform/shape' type=Const>, <tf.Operation 'random_uniform/min' type=Const>, <tf.Operation 'random_uniform/max' type=Const>, <tf.Operation 'random_uniform/RandomUniform' type=RandomUniform>, <tf.Operation 'random_uniform/sub' type=Sub>, <tf.Operation 'random_uniform/mul' type=Mul>, <tf.Operation 'random_uniform' type=Add>, <tf.Operation 'Variable_1' type=VariableV2>, <tf.Operation 'Variable_1/Assign' type=Assign>, <tf.Operation 'Variable_1/read' type=Identity>, <tf.Operation 'MatMul' type=MatMul>, <tf.Operation 'Softmax' type=Softmax>, <tf.Operation 'Const_2' type=Const>, <tf.Operation 'random_uniform_1/shape' type=Const>, <tf.Operation 'random_uniform_1/min' type=Const>, <tf.Operation 'random_uniform_1/max' type=Const>, <tf.Operation 'random_uniform_1/RandomUniform' type=RandomUniform>, <tf.Operation 'random_uniform_1/sub' type=Sub>, <tf.Operation 'random_uniform_1/mul' type=Mul>, <tf.Operation 'random_uniform_1' type=Add>, <tf.Operation 'Variable_2' type=VariableV2>, <tf.Operation 'Variable_2/Assign' type=Assign>, <tf.Operation 'Variable_2/read' type=Identity>, <tf.Operation 'MatMul_1' type=MatMul>, <tf.Operation 'Softmax_1' type=Softmax>, <tf.Operation 'Const_3' type=Const>, <tf.Operation 'random_uniform_2/shape' type=Const>, <tf.Operation 'random_uniform_2/min' type=Const>, <tf.Operation 'random_uniform_2/max' type=Const>, <tf.Operation 'random_uniform_2/RandomUniform' type=RandomUniform>, <tf.Operation 'random_uniform_2/sub' type=Sub>, <tf.Operation 'random_uniform_2/mul' type=Mul>, <tf.Operation 'random_uniform_2' type=Add>, <tf.Operation 'Variable_3' type=VariableV2>, <tf.Operation 'Variable_3/Assign' type=Assign>, <tf.Operation 'Variable_3/read' type=Identity>, <tf.Operation 'MatMul_2' type=MatMul>, <tf.Operation 'Softmax_2' type=Softmax>, <tf.Operation 'Const_4' type=Const>, <tf.Operation 'random_uniform_3/shape' type=Const>, <tf.Operation 'random_uniform_3/min' type=Const>, <tf.Operation 'random_uniform_3/max' type=Const>, <tf.Operation 'random_uniform_3/RandomUniform' type=RandomUniform>, <tf.Operation 'random_uniform_3/sub' type=Sub>, <tf.Operation 'random_uniform_3/mul' type=Mul>, <tf.Operation 'random_uniform_3' type=Add>, <tf.Operation 'Variable_4' type=VariableV2>, <tf.Operation 'Variable_4/Assign' type=Assign>, <tf.Operation 'Variable_4/read' type=Identity>, <tf.Operation 'MatMul_3' type=MatMul>, <tf.Operation 'Softmax_3' type=Softmax>, <tf.Operation 'Placeholder' type=Placeholder>, <tf.Operation 'Square' type=Square>, <tf.Operation 'Placeholder_1' type=Placeholder>, <tf.Operation 'Square_1' type=Square>, <tf.Operation 'random_uniform_4/shape' type=Const>, <tf.Operation 'random_uniform_4/min' type=Const>, <tf.Operation 'random_uniform_4/max' type=Const>, <tf.Operation 'random_uniform_4/RandomUniform' type=RandomUniform>, <tf.Operation 'random_uniform_4/sub' type=Sub>, <tf.Operation 'random_uniform_4/mul' type=Mul>, <tf.Operation 'random_uniform_4' type=Add>, <tf.Operation 'MatMul_4/a' type=Const>, <tf.Operation 'MatMul_4' type=MatMul>, <tf.Operation 'random_uniform_5/shape' type=Const>, <tf.Operation 'random_uniform_5/min' type=Const>, <tf.Operation 'random_uniform_5/max' type=Const>, <tf.Operation 'random_uniform_5/RandomUniform' type=RandomUniform>, <tf.Operation 'random_uniform_5/sub' type=Sub>, <tf.Operation 'random_uniform_5/mul' type=Mul>, <tf.Operation 'random_uniform_5' type=Add>, <tf.Operation 'MatMul_5/a' type=Const>, <tf.Operation 'MatMul_5' type=MatMul>, <tf.Operation 'random_uniform_6/shape' type=Const>, <tf.Operation 'random_uniform_6/min' type=Const>, <tf.Operation 'random_uniform_6/max' type=Const>, <tf.Operation 'random_uniform_6/RandomUniform' type=RandomUniform>, <tf.Operation 'random_uniform_6/sub' type=Sub>, <tf.Operation 'random_uniform_6/mul' type=Mul>, <tf.Operation 'random_uniform_6' type=Add>, <tf.Operation 'MatMul_6/a' type=Const>, <tf.Operation 'MatMul_6' type=MatMul>, <tf.Operation 'random_uniform_7/shape' type=Const>, <tf.Operation 'random_uniform_7/min' type=Const>, <tf.Operation 'random_uniform_7/max' type=Const>, <tf.Operation 'random_uniform_7/RandomUniform' type=RandomUniform>, <tf.Operation 'random_uniform_7/sub' type=Sub>, <tf.Operation 'random_uniform_7/mul' type=Mul>, <tf.Operation 'random_uniform_7' type=Add>, <tf.Operation 'MatMul_7/a' type=Const>, <tf.Operation 'MatMul_7' type=MatMul>, <tf.Operation 'random_uniform_8/shape' type=Const>, <tf.Operation 'random_uniform_8/min' type=Const>, <tf.Operation 'random_uniform_8/max' type=Const>, <tf.Operation 'random_uniform_8/RandomUniform' type=RandomUniform>, <tf.Operation 'random_uniform_8/sub' type=Sub>, <tf.Operation 'random_uniform_8/mul' type=Mul>, <tf.Operation 'random_uniform_8' type=Add>, <tf.Operation 'MatMul_8/a' type=Const>, <tf.Operation 'MatMul_8' type=MatMul>, <tf.Operation 'random_uniform_9/shape' type=Const>, <tf.Operation 'random_uniform_9/min' type=Const>, <tf.Operation 'random_uniform_9/max' type=Const>, <tf.Operation 'random_uniform_9/RandomUniform' type=RandomUniform>, <tf.Operation 'random_uniform_9/sub' type=Sub>, <tf.Operation 'random_uniform_9/mul' type=Mul>, <tf.Operation 'random_uniform_9' type=Add>, <tf.Operation 'MatMul_9/a' type=Const>, <tf.Operation 'MatMul_9' type=MatMul>, <tf.Operation 'random_uniform_10/shape' type=Const>, <tf.Operation 'random_uniform_10/min' type=Const>, <tf.Operation 'random_uniform_10/max' type=Const>, <tf.Operation 'random_uniform_10/RandomUniform' type=RandomUniform>, <tf.Operation 'random_uniform_10/sub' type=Sub>, <tf.Operation 'random_uniform_10/mul' type=Mul>, <tf.Operation 'random_uniform_10' type=Add>, <tf.Operation 'MatMul_10/a' type=Const>, <tf.Operation 'MatMul_10' type=MatMul>, <tf.Operation 'random_uniform_11/shape' type=Const>, <tf.Operation 'random_uniform_11/min' type=Const>, <tf.Operation 'random_uniform_11/max' type=Const>, <tf.Operation 'random_uniform_11/RandomUniform' type=RandomUniform>, <tf.Operation 'random_uniform_11/sub' type=Sub>, <tf.Operation 'random_uniform_11/mul' type=Mul>, <tf.Operation 'random_uniform_11' type=Add>, <tf.Operation 'MatMul_11/a' type=Const>, <tf.Operation 'MatMul_11' type=MatMul>]\n"
     ]
    }
   ],
   "source": [
    "g = tf.get_default_graph()\n",
    "print(g.get_operations())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_1.close()\n",
    "sess_2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summary\n",
    "\n",
    "+ tensorflow is designed to have graphs of calculations and a session / engine in which to execute them\n",
    "+ the graph interface is a class `tf.Graph`\n",
    "    + one exists by default and all tensorflow items are added to it\n",
    "    + you can create separate graphs using `tf.Graph` directly\n",
    "+ operations and tensors have names and those names may possibly differentiate *scopes*, localized namespaces\n",
    "+ tensorflow gives you control over the hardware and networked resources used for a computation\n",
    "+ operations are executed in sessions\n",
    "    + sessions can be configured\n",
    "    + sessions can be running on remote servers\n",
    "+ tensorboard allows you to visualize graphs as diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
